# âš¡ CIS File Search - Spot Instanceä¸­æ–­å¯¾å¿œã‚¬ã‚¤ãƒ‰

## ğŸ¯ æ¦‚è¦

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€EC2 Spot Instanceã®ä¸­æ–­é€šçŸ¥ã«å¯¾å¿œã—ã€å‡¦ç†ä¸­ã®ãƒ‡ãƒ¼ã‚¿ã‚’å®‰å…¨ã«é€€é¿ã™ã‚‹ä»•çµ„ã¿ã‚’å®Ÿè£…ã—ã¾ã™ã€‚AWSæä¾›ã®2åˆ†é–“ã®çŒ¶äºˆæœŸé–“ã‚’æœ€å¤§é™æ´»ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ãƒ­ã‚¹ã‚’é˜²ãã¾ã™ã€‚

## ğŸ“Š Spot Instanceä¸­æ–­ã®ä»•çµ„ã¿

### ä¸­æ–­é€šçŸ¥ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³

```
T-2åˆ†: AWS ãŒä¸­æ–­é€šçŸ¥ã‚’é€ä¿¡
       â”œâ”€ EC2 Metadata Service ã«é€šçŸ¥
       â”œâ”€ EventBridge ã«ã‚¤ãƒ™ãƒ³ãƒˆç™ºè¡Œ
       â””â”€ CloudWatch Events ç™ºç«

T-0åˆ†: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¼·åˆ¶çµ‚äº†
```

### ä¸­æ–­ã®ä¸»ãªç†ç”±

1. **ä¾¡æ ¼å¤‰å‹•** - Spotä¾¡æ ¼ãŒBidä¾¡æ ¼ã‚’è¶…éï¼ˆç¾åœ¨ã¯è‡ªå‹•å…¥æœ­ã®ãŸã‚ç¨€ï¼‰
2. **å®¹é‡ä¸è¶³** - AWSãŒOn-Demand/Reservedç”¨ã«å®¹é‡ã‚’å¿…è¦
3. **åˆ¶ç´„é•å** - Instance typeã®åˆ¶ç´„ã‚°ãƒ«ãƒ¼ãƒ—é•å

## ğŸ›¡ï¸ 3å±¤é˜²å¾¡ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ãƒ¬ã‚¤ãƒ¤ãƒ¼1: Capacity Rebalancingï¼ˆäºˆé˜²çš„å¯¾å¿œï¼‰

```yaml
Auto Scaling Groupè¨­å®š:
  Capacity Rebalancing: Enabled
  åŠ¹æœ:
    - ä¸­æ–­ãƒªã‚¹ã‚¯ã®é«˜ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’äº‹å‰ã«äº¤æ›
    - ä¸­æ–­é€šçŸ¥å‰ã«æ–°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’èµ·å‹•
    - ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ãªç§»è¡Œ
```

### ãƒ¬ã‚¤ãƒ¤ãƒ¼2: Instance Metadataç›£è¦–ï¼ˆãƒªã‚¢ã‚¯ãƒ†ã‚£ãƒ–å¯¾å¿œï¼‰

```bash
#!/bin/bash
# ä¸­æ–­é€šçŸ¥ã‚’5ç§’ã”ã¨ã«ãƒã‚§ãƒƒã‚¯
while true; do
  TOKEN=$(curl -X PUT "http://169.254.169.254/latest/api/token" \
    -H "X-aws-ec2-metadata-token-ttl-seconds: 21600" 2>/dev/null)

  if curl -H "X-aws-ec2-metadata-token: $TOKEN" \
    -f http://169.254.169.254/latest/meta-data/spot/instance-action \
    2>/dev/null; then
    # ä¸­æ–­å‡¦ç†é–‹å§‹
    /usr/local/bin/handle-spot-interruption.sh
    break
  fi
  sleep 5
done
```

### ãƒ¬ã‚¤ãƒ¤ãƒ¼3: EventBridgeçµ±åˆï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰

```python
# Lambdaé–¢æ•°ã§EventBridgeçµŒç”±ã®é€šçŸ¥ã‚’å‡¦ç†
def lambda_handler(event, context):
    if event['detail-type'] == 'EC2 Spot Instance Interruption Warning':
        instance_id = event['detail']['instance-id']
        # Systems Manager Run Commandã§ä¸­æ–­å‡¦ç†ã‚’å®Ÿè¡Œ
        ssm_client.send_command(
            InstanceIds=[instance_id],
            DocumentName='AWS-RunShellScript',
            Parameters={'commands': ['/usr/local/bin/handle-spot-interruption.sh']}
        )
```

## ğŸ”§ å®Ÿè£…ã‚³ãƒ¼ãƒ‰

### 1. ä¸­æ–­ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (`handle-spot-interruption.sh`)

```bash
#!/bin/bash
# ========================================
# Spot Instance Interruption Handler
# 2åˆ†ä»¥å†…ã«å…¨å‡¦ç†ã‚’å®Œäº†ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
# ========================================

set -e

LOG_FILE="/var/log/spot-interruption.log"
INSTANCE_ID=$(ec2-metadata --instance-id | cut -d " " -f 2)
REGION=$(ec2-metadata --availability-zone | cut -d " " -f 2 | sed 's/[a-z]$//')
TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

# ãƒ­ã‚°è¨˜éŒ²
log() {
    echo "[$(date -u +"%Y-%m-%d %H:%M:%S")] $1" | tee -a $LOG_FILE
}

log "=== SPOT INTERRUPTION DETECTED ==="
log "Instance ID: $INSTANCE_ID"
log "Time remaining: ~120 seconds"

# ========================================
# Step 1: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¸ã®é€šçŸ¥ (5ç§’)
# ========================================
log "Step 1: Notifying application..."

# SIGTERMã‚·ã‚°ãƒŠãƒ«ã‚’é€ä¿¡ã—ã¦ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ã‚’é–‹å§‹
systemctl stop cis-file-processor --no-block

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³é€šçŸ¥
echo "SPOT_INTERRUPTION" > /var/app/cis-file-processor/shutdown.signal

# CloudWatchãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡
aws cloudwatch put-metric-data \
    --namespace "CIS/FileProcessor" \
    --metric-name "SpotInterruption" \
    --value 1 \
    --dimensions InstanceId=$INSTANCE_ID \
    --region $REGION &

# ========================================
# Step 2: å‡¦ç†ä¸­ãƒ‡ãƒ¼ã‚¿ã®é€€é¿ (30ç§’)
# ========================================
log "Step 2: Saving in-progress data..."

# å‡¦ç†ä¸­ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’S3ã«é€€é¿
TEMP_BUCKET="cis-filesearch-temp"
INTERRUPTED_PREFIX="interrupted/$INSTANCE_ID/$TIMESTAMP"

# å‡¦ç†ä¸­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š
PROCESSING_DIR="/tmp/processing"
if [ -d "$PROCESSING_DIR" ]; then
    FILE_COUNT=$(find $PROCESSING_DIR -type f | wc -l)
    log "Found $FILE_COUNT files in processing"

    if [ $FILE_COUNT -gt 0 ]; then
        # S3ã«é«˜é€Ÿã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰
        aws s3 sync $PROCESSING_DIR \
            s3://$TEMP_BUCKET/$INTERRUPTED_PREFIX/ \
            --storage-class STANDARD_IA \
            --metadata "interruption-time=$TIMESTAMP,instance-id=$INSTANCE_ID" \
            --only-show-errors &

        S3_PID=$!

        # æœ€å¤§30ç§’å¾…æ©Ÿ
        timeout 30 bash -c "while kill -0 $S3_PID 2>/dev/null; do sleep 1; done"

        if kill -0 $S3_PID 2>/dev/null; then
            log "WARNING: S3 upload timeout, killing process"
            kill -9 $S3_PID
        else
            log "Successfully uploaded processing files to S3"
        fi
    fi
fi

# ========================================
# Step 3: å‡¦ç†çŠ¶æ…‹ã®ä¿å­˜ (10ç§’)
# ========================================
log "Step 3: Saving processing state..."

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’DynamoDBã«ä¿å­˜
STATE_FILE="/var/app/cis-file-processor/state.json"
if [ -f "$STATE_FILE" ]; then
    # Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã§çŠ¶æ…‹ä¿å­˜
    python3 <<EOF
import json
import boto3
from datetime import datetime

dynamodb = boto3.resource('dynamodb', region_name='$REGION')
table = dynamodb.Table('CIS-ProcessingState')

with open('$STATE_FILE', 'r') as f:
    state = json.load(f)

# ä¸­æ–­æƒ…å ±ã‚’è¿½åŠ 
state['interruption'] = {
    'timestamp': '$TIMESTAMP',
    'instance_id': '$INSTANCE_ID'
}

# DynamoDBã«ä¿å­˜
table.put_item(Item=state)
print("State saved to DynamoDB")
EOF
fi

# ========================================
# Step 4: SQSãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å¯è¦–æ€§å»¶é•· (10ç§’)
# ========================================
log "Step 4: Extending SQS message visibility..."

# å‡¦ç†ä¸­ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDã‚’å–å¾—
RECEIPT_HANDLES_FILE="/var/app/cis-file-processor/active_receipts.json"
if [ -f "$RECEIPT_HANDLES_FILE" ]; then
    python3 <<EOF
import json
import boto3

sqs = boto3.client('sqs', region_name='$REGION')
queue_url = 'https://sqs.$REGION.amazonaws.com/123456789012/CIS-FileProcessing-Queue'

with open('$RECEIPT_HANDLES_FILE', 'r') as f:
    receipts = json.load(f)

for receipt_handle in receipts:
    try:
        # å¯è¦–æ€§ã‚’5åˆ†å»¶é•·ï¼ˆåˆ¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒå‡¦ç†ã§ãã‚‹ã‚ˆã†ã«ï¼‰
        sqs.change_message_visibility(
            QueueUrl=queue_url,
            ReceiptHandle=receipt_handle,
            VisibilityTimeout=300
        )
    except Exception as e:
        print(f"Failed to extend visibility: {e}")
EOF
    log "Extended visibility for active messages"
fi

# ========================================
# Step 5: ãƒ­ã‚°ã®ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ (5ç§’)
# ========================================
log "Step 5: Flushing logs..."

# CloudWatch Agentã®ãƒ­ã‚°ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
systemctl reload amazon-cloudwatch-agent || true

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°ã‚’å¼·åˆ¶ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
if [ -f "/var/app/cis-file-processor/logs/application.log" ]; then
    # æœ€å¾Œã®100è¡Œã‚’S3ã«ä¿å­˜
    tail -n 100 /var/app/cis-file-processor/logs/application.log | \
        aws s3 cp - s3://$TEMP_BUCKET/$INTERRUPTED_PREFIX/final_logs.txt
fi

# ========================================
# Step 6: Auto Scalingé€šçŸ¥ (5ç§’)
# ========================================
log "Step 6: Notifying Auto Scaling Group..."

# ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Œäº†
ASG_NAME="CIS-FileProcessor-ASG"
LIFECYCLE_HOOK="CIS-GracefulTermination"

aws autoscaling complete-lifecycle-action \
    --lifecycle-action-result CONTINUE \
    --lifecycle-hook-name $LIFECYCLE_HOOK \
    --auto-scaling-group-name $ASG_NAME \
    --instance-id $INSTANCE_ID \
    --region $REGION || true

# ========================================
# Step 7: æœ€çµ‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— (10ç§’)
# ========================================
log "Step 7: Final cleanup..."

# ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
rm -rf /tmp/processing/*
rm -f /var/app/cis-file-processor/active_receipts.json
rm -f /var/app/cis-file-processor/state.json

# æœ€çµ‚ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡
aws cloudwatch put-metric-data \
    --namespace "CIS/FileProcessor" \
    --metric-name "SpotInterruptionHandled" \
    --value 1 \
    --dimensions InstanceId=$INSTANCE_ID \
    --region $REGION

log "=== INTERRUPTION HANDLING COMPLETE ==="
log "Total time: $(($(date +%s) - $(date -d "$TIMESTAMP" +%s))) seconds"
log "Instance will terminate in ~$((120 - $(date +%s) + $(date -d "$TIMESTAMP" +%s))) seconds"

# æ­£å¸¸çµ‚äº†
exit 0
```

### 2. Python Appã§ã®ä¸­æ–­å¯¾å¿œ (`interruption_handler.py`)

```python
"""Spot Instanceä¸­æ–­ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆPythonã‚¢ãƒ—ãƒªå´ï¼‰"""

import os
import signal
import json
import time
import threading
from typing import Dict, Any, Optional
import boto3
import structlog

logger = structlog.get_logger()

class SpotInterruptionHandler:
    """Spot Instanceä¸­æ–­ã‚’å‡¦ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self, app_state: Dict[str, Any]):
        self.app_state = app_state
        self.s3_client = boto3.client('s3')
        self.dynamodb = boto3.resource('dynamodb')
        self.instance_id = self._get_instance_id()
        self.shutdown_event = threading.Event()

        # SIGTERMãƒãƒ³ãƒ‰ãƒ©ãƒ¼ç™»éŒ²
        signal.signal(signal.SIGTERM, self._sigterm_handler)

        # ä¸­æ–­ãƒã‚§ãƒƒã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        self.monitor_thread = threading.Thread(
            target=self._monitor_interruption,
            daemon=True
        )
        self.monitor_thread.start()

    def _get_instance_id(self) -> str:
        """ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹IDã‚’å–å¾—"""
        try:
            import requests
            token = requests.put(
                "http://169.254.169.254/latest/api/token",
                headers={"X-aws-ec2-metadata-token-ttl-seconds": "21600"}
            ).text

            return requests.get(
                "http://169.254.169.254/latest/meta-data/instance-id",
                headers={"X-aws-ec2-metadata-token": token}
            ).text
        except Exception:
            return "unknown"

    def _sigterm_handler(self, signum, frame):
        """SIGTERMã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
        logger.warning("Received SIGTERM, initiating graceful shutdown")
        self.shutdown_event.set()
        self.handle_interruption()

    def _monitor_interruption(self):
        """ä¸­æ–­é€šçŸ¥ã‚’ç›£è¦–"""
        import requests

        while not self.shutdown_event.is_set():
            try:
                # ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—
                token = requests.put(
                    "http://169.254.169.254/latest/api/token",
                    headers={"X-aws-ec2-metadata-token-ttl-seconds": "21600"},
                    timeout=1
                ).text

                # ä¸­æ–­é€šçŸ¥ãƒã‚§ãƒƒã‚¯
                response = requests.get(
                    "http://169.254.169.254/latest/meta-data/spot/instance-action",
                    headers={"X-aws-ec2-metadata-token": token},
                    timeout=1
                )

                if response.status_code == 200:
                    interruption_data = response.json()
                    logger.critical("SPOT INTERRUPTION DETECTED",
                                  action=interruption_data.get('action'),
                                  time=interruption_data.get('time'))
                    self.handle_interruption()
                    break

            except requests.exceptions.RequestException:
                # 404ã¯æ­£å¸¸ï¼ˆä¸­æ–­ãªã—ï¼‰
                pass
            except Exception as e:
                logger.error("Error monitoring interruption", error=str(e))

            time.sleep(5)

    def handle_interruption(self):
        """ä¸­æ–­å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
        start_time = time.time()
        logger.info("Starting interruption handling")

        try:
            # 1. æ–°è¦ã‚¿ã‚¹ã‚¯å—ä»˜ã‚’åœæ­¢
            self._stop_accepting_tasks()

            # 2. å‡¦ç†ä¸­ã‚¿ã‚¹ã‚¯ã‚’å®‰å…¨ã«åœæ­¢
            self._stop_current_tasks()

            # 3. çŠ¶æ…‹ã‚’ä¿å­˜
            self._save_state()

            # 4. ãƒ‡ãƒ¼ã‚¿ã‚’é€€é¿
            self._evacuate_data()

            # 5. ãƒ­ã‚°ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
            self._flush_logs()

            elapsed = time.time() - start_time
            logger.info(f"Interruption handling completed in {elapsed:.2f} seconds")

        except Exception as e:
            logger.error("Error during interruption handling", error=str(e))

    def _stop_accepting_tasks(self):
        """æ–°è¦ã‚¿ã‚¹ã‚¯ã®å—ä»˜ã‚’åœæ­¢"""
        self.app_state['accepting_tasks'] = False
        logger.info("Stopped accepting new tasks")

    def _stop_current_tasks(self):
        """å‡¦ç†ä¸­ã‚¿ã‚¹ã‚¯ã‚’åœæ­¢"""
        active_tasks = self.app_state.get('active_tasks', [])

        for task in active_tasks:
            try:
                # ã‚¿ã‚¹ã‚¯ã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã‚·ã‚°ãƒŠãƒ«ã‚’é€ä¿¡
                task['cancelled'] = True

                # å‡¦ç†ä¸­ãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’ä¿å­˜
                if 'file_path' in task:
                    self._save_partial_result(task)

            except Exception as e:
                logger.error(f"Error stopping task {task.get('id')}", error=str(e))

        logger.info(f"Stopped {len(active_tasks)} active tasks")

    def _save_partial_result(self, task: Dict[str, Any]):
        """éƒ¨åˆ†çš„ãªå‡¦ç†çµæœã‚’ä¿å­˜"""
        try:
            partial_result = {
                'task_id': task.get('id'),
                'file_path': task.get('file_path'),
                'progress': task.get('progress', 0),
                'partial_text': task.get('extracted_text', ''),
                'instance_id': self.instance_id,
                'timestamp': time.time()
            }

            # S3ã«ä¿å­˜
            self.s3_client.put_object(
                Bucket='cis-filesearch-temp',
                Key=f"partial/{self.instance_id}/{task['id']}.json",
                Body=json.dumps(partial_result),
                StorageClass='STANDARD_IA'
            )

        except Exception as e:
            logger.error(f"Error saving partial result for task {task.get('id')}",
                       error=str(e))

    def _save_state(self):
        """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ä¿å­˜"""
        try:
            state = {
                'instance_id': self.instance_id,
                'timestamp': time.time(),
                'active_tasks': self.app_state.get('active_tasks', []),
                'processed_count': self.app_state.get('processed_count', 0),
                'error_count': self.app_state.get('error_count', 0),
                'queue_receipts': self.app_state.get('queue_receipts', [])
            }

            # DynamoDBã«ä¿å­˜
            table = self.dynamodb.Table('CIS-ProcessingState')
            table.put_item(Item=state)

            # ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚‚ä¿å­˜ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰
            with open('/var/app/cis-file-processor/state.json', 'w') as f:
                json.dump(state, f)

            logger.info("Application state saved")

        except Exception as e:
            logger.error("Error saving state", error=str(e))

    def _evacuate_data(self):
        """å‡¦ç†ä¸­ãƒ‡ãƒ¼ã‚¿ã‚’é€€é¿"""
        try:
            processing_dir = '/tmp/processing'
            if os.path.exists(processing_dir):
                files = os.listdir(processing_dir)

                for file in files:
                    file_path = os.path.join(processing_dir, file)
                    s3_key = f"interrupted/{self.instance_id}/{file}"

                    # S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                    self.s3_client.upload_file(
                        file_path,
                        'cis-filesearch-temp',
                        s3_key,
                        ExtraArgs={'StorageClass': 'STANDARD_IA'}
                    )

                logger.info(f"Evacuated {len(files)} files to S3")

        except Exception as e:
            logger.error("Error evacuating data", error=str(e))

    def _flush_logs(self):
        """ãƒ­ã‚°ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥"""
        try:
            # structlogã®ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
            import logging
            for handler in logging.getLogger().handlers:
                handler.flush()

            logger.info("Logs flushed")

        except Exception as e:
            logger.error("Error flushing logs", error=str(e))
```

### 3. EventBridge Ruleè¨­å®š

```json
{
  "Name": "CIS-SpotInterruptionHandler",
  "EventPattern": {
    "source": ["aws.ec2"],
    "detail-type": ["EC2 Spot Instance Interruption Warning"],
    "detail": {
      "instance-action": ["terminate", "stop", "hibernate"]
    }
  },
  "State": "ENABLED",
  "Targets": [
    {
      "Arn": "arn:aws:lambda:ap-northeast-1:123456789012:function:CIS-SpotInterruptionHandler",
      "Id": "1"
    },
    {
      "Arn": "arn:aws:sns:ap-northeast-1:123456789012:CIS-Alerts",
      "Id": "2"
    }
  ]
}
```

## ğŸ“Š ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ

### CloudWatch Dashboardè¨­å®š

```json
{
  "name": "CIS-SpotInterruptions",
  "widgets": [
    {
      "type": "metric",
      "properties": {
        "title": "Spot Interruptions",
        "metrics": [
          ["CIS/FileProcessor", "SpotInterruption", {"stat": "Sum"}],
          [".", "SpotInterruptionHandled", {"stat": "Sum"}],
          ["AWS/EC2", "SpotInstanceInterruptions", {"stat": "Sum"}]
        ],
        "period": 300,
        "region": "ap-northeast-1"
      }
    },
    {
      "type": "metric",
      "properties": {
        "title": "Data Evacuation Success Rate",
        "metrics": [
          ["CIS/FileProcessor", "DataEvacuationSuccess", {"stat": "Sum"}],
          [".", "DataEvacuationFailure", {"stat": "Sum"}]
        ],
        "period": 300,
        "region": "ap-northeast-1"
      }
    }
  ]
}
```

### ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š

```yaml
SpotInterruptionAlarm:
  MetricName: SpotInterruption
  Namespace: CIS/FileProcessor
  Statistic: Sum
  Period: 60
  EvaluationPeriods: 1
  Threshold: 1
  ComparisonOperator: GreaterThanOrEqualToThreshold
  AlarmActions:
    - !Ref SNSTopic
  AlarmDescription: "Spot Instance interruption detected"
```

## ğŸ” ãƒ†ã‚¹ãƒˆã¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

### ä¸­æ–­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# Spotä¸­æ–­ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ

# æ¨¡æ“¬ä¸­æ–­é€šçŸ¥ã‚’ä½œæˆ
cat > /tmp/mock-interruption.json <<EOF
{
  "action": "terminate",
  "time": "$(date -u -d '+2 minutes' +"%Y-%m-%dT%H:%M:%SZ")"
}
EOF

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ¢ãƒƒã‚¯ã‚’èµ·å‹•
python3 -m http.server 8080 &
SERVER_PID=$!

# ä¸­æ–­ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ãƒ†ã‚¹ãƒˆ
/usr/local/bin/handle-spot-interruption.sh

# ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
kill $SERVER_PID
rm /tmp/mock-interruption.json
```

### è² è·ãƒ†ã‚¹ãƒˆä¸‹ã§ã®ä¸­æ–­ãƒ†ã‚¹ãƒˆ

```python
"""è² è·ã‚’ã‹ã‘ãªãŒã‚‰ä¸­æ–­ã‚’ãƒ†ã‚¹ãƒˆ"""

import concurrent.futures
import time
import subprocess

def process_file(file_id):
    """ãƒ€ãƒŸãƒ¼ã®ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†"""
    time.sleep(10)  # å‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    return f"File {file_id} processed"

# 100ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸¦åˆ—å‡¦ç†
with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
    futures = [executor.submit(process_file, i) for i in range(100)]

    # å‡¦ç†ä¸­ã«ä¸­æ–­ã‚’ãƒˆãƒªã‚¬ãƒ¼
    time.sleep(5)
    subprocess.run(['kill', '-TERM', str(os.getpid())])

    # çµæœã‚’ç¢ºèª
    for future in futures:
        try:
            result = future.result(timeout=1)
            print(result)
        except concurrent.futures.TimeoutError:
            print("Processing interrupted")
```

## âœ… ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### DO's âœ…

1. **2åˆ†ãƒ«ãƒ¼ãƒ«ã®å³å®ˆ** - å…¨å‡¦ç†ã‚’120ç§’ä»¥å†…ã«å®Œäº†
2. **ä¸¦åˆ—å‡¦ç†** - S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨DBä¿å­˜ã‚’ä¸¦åˆ—å®Ÿè¡Œ
3. **å„ªå…ˆé †ä½ä»˜ã‘** - é‡è¦ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é †ã«é€€é¿
4. **å†ªç­‰æ€§** - ä¸­æ–­å‡¦ç†ãŒè¤‡æ•°å›å®Ÿè¡Œã•ã‚Œã¦ã‚‚å®‰å…¨
5. **ãƒ­ã‚°è¨˜éŒ²** - å…¨ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè¡Œæ™‚é–“ã‚’è¨˜éŒ²

### DON'Ts âŒ

1. **å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã®åŒæœŸã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰** - éåŒæœŸã¾ãŸã¯ãƒãƒ«ãƒãƒ‘ãƒ¼ãƒˆä½¿ç”¨
2. **ç„¡é™ãƒ«ãƒ¼ãƒ—** - ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’å¿…ãšè¨­å®š
3. **ã‚¨ãƒ©ãƒ¼ã§ã®åœæ­¢** - ã‚¨ãƒ©ãƒ¼ã‚’ã‚­ãƒ£ãƒƒãƒã—ã¦ç¶šè¡Œ
4. **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¾…æ©Ÿ** - ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’çŸ­ãè¨­å®š

## ğŸ“ˆ ã‚³ã‚¹ãƒˆå½±éŸ¿åˆ†æ

### ä¸­æ–­ç‡ã«ã‚ˆã‚‹æœˆé–“ã‚³ã‚¹ãƒˆå½±éŸ¿

| ä¸­æ–­ç‡/æ—¥ | å†å‡¦ç†ã‚³ã‚¹ãƒˆ | ãƒ‡ãƒ¼ã‚¿è»¢é€ã‚³ã‚¹ãƒˆ | åˆè¨ˆè¿½åŠ ã‚³ã‚¹ãƒˆ |
|----------|------------|---------------|--------------|
| 1% | $0.50 | $0.10 | $0.60 |
| 5% | $2.50 | $0.50 | $3.00 |
| 10% | $5.00 | $1.00 | $6.00 |

### ROIè¨ˆç®—

```
Spotå‰²å¼•: 70% ($86.40/æœˆã®ç¯€ç´„)
ä¸­æ–­å¯¾å¿œã‚³ã‚¹ãƒˆ: ~$3.00/æœˆ
å®Ÿè³ªç¯€ç´„é¡: $83.40/æœˆ (96.5%ã®ã‚³ã‚¹ãƒˆåŠ¹ç‡)
```

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ä¸­æ–­å‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œãªã„

```bash
# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚µãƒ¼ãƒ“ã‚¹ã®ç¢ºèª
curl -I http://169.254.169.254/latest/meta-data/

# IMDSv2ãƒˆãƒ¼ã‚¯ãƒ³ã®ç¢ºèª
TOKEN=$(curl -X PUT "http://169.254.169.254/latest/api/token" \
  -H "X-aws-ec2-metadata-token-ttl-seconds: 21600")
echo $TOKEN

# ä¸­æ–­é€šçŸ¥ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ç¢ºèª
curl -H "X-aws-ec2-metadata-token: $TOKEN" \
  http://169.254.169.254/latest/meta-data/spot/instance-action
```

### ãƒ‡ãƒ¼ã‚¿é€€é¿ãŒé–“ã«åˆã‚ãªã„

```python
# å„ªå…ˆåº¦ä»˜ãã®é€€é¿
import heapq

class PriorityEvacuation:
    def __init__(self):
        self.queue = []

    def add_file(self, priority, file_path, size):
        # å°ã•ãã¦é‡è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’å„ªå…ˆ
        score = priority / (size + 1)
        heapq.heappush(self.queue, (-score, file_path))

    def evacuate(self, time_limit=100):
        evacuated = []
        start_time = time.time()

        while self.queue and (time.time() - start_time) < time_limit:
            _, file_path = heapq.heappop(self.queue)
            # S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            evacuated.append(file_path)

        return evacuated
```

## ğŸ“š å‚è€ƒãƒªãƒ³ã‚¯

- [EC2 Spot Interruptions](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-interruptions.html)
- [Capacity Rebalancing](https://docs.aws.amazon.com/autoscaling/ec2/userguide/capacity-rebalance.html)
- [Instance Metadata Service v2](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html)
- [EventBridge Spot Events](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-instance-interruptions.html#spot-instance-interruption-notices)

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

Spot Instanceä¸­æ–­å¯¾å¿œã®å®Ÿè£…å¾Œã¯ã€æœ¬ç•ªç’°å¢ƒã§ã®ãƒ†ã‚¹ãƒˆã¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™ã€‚é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã§ä¸­æ–­ç‡ã¨å¯¾å¿œæˆåŠŸç‡ã‚’è¿½è·¡ã—ã€ç¶™ç¶šçš„ã«æ”¹å–„ã—ã¦ã„ãã¾ã™ã€‚

ã“ã‚Œã§Phase 2ã®EC2ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã‚¬ã‚¤ãƒ‰ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼