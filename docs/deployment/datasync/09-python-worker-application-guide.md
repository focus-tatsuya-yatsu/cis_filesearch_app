# ğŸ CIS File Search - Python Worker Applicationå®Ÿè£…ã‚¬ã‚¤ãƒ‰

## ğŸ¯ æ¦‚è¦

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€EC2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä¸Šã§å‹•ä½œã™ã‚‹Python Workerã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Œå…¨ãªå®Ÿè£…ã‚’æä¾›ã—ã¾ã™ã€‚SQSãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†ã€Tesseract OCRã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã€å„ç¨®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®å¯¾å¿œã‚’å«ã¿ã¾ã™ã€‚

## ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
/var/app/cis-file-processor/
â”œâ”€â”€ main.py                 # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”œâ”€â”€ config.py              # è¨­å®šç®¡ç†
â”œâ”€â”€ processors/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py           # åŸºåº•ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚¯ãƒ©ã‚¹
â”‚   â”œâ”€â”€ pdf_processor.py  # PDFå‡¦ç†
â”‚   â”œâ”€â”€ image_processor.py # ç”»åƒå‡¦ç†ï¼ˆOCRï¼‰
â”‚   â”œâ”€â”€ office_processor.py # Officeæ–‡æ›¸å‡¦ç†
â”‚   â””â”€â”€ text_processor.py  # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sqs_service.py    # SQSæ“ä½œ
â”‚   â”œâ”€â”€ s3_service.py     # S3æ“ä½œ
â”‚   â”œâ”€â”€ opensearch_service.py # OpenSearchç´¢å¼•
â”‚   â””â”€â”€ metrics_service.py # CloudWatchãƒ¡ãƒˆãƒªã‚¯ã‚¹
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py         # ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
â”‚   â””â”€â”€ exceptions.py     # ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–
â”œâ”€â”€ requirements.txt       # ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
â””â”€â”€ tests/                # ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
```

## ğŸ”§ å®Ÿè£…ã‚³ãƒ¼ãƒ‰

### 1. ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ (`main.py`)

```python
#!/usr/bin/env python3
"""
CIS File Processor - Main Entry Point
SQSãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¦OpenSearchã«ç´¢å¼•ä»˜ã‘ã™ã‚‹
"""

import os
import sys
import signal
import time
import json
import threading
from typing import Optional, Dict, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
import structlog

from config import Config
from services.sqs_service import SQSService
from services.s3_service import S3Service
from services.opensearch_service import OpenSearchService
from services.metrics_service import MetricsService
from processors import ProcessorFactory
from utils.logger import setup_logging

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = setup_logging()

class FileProcessor:
    """ãƒ¡ã‚¤ãƒ³ã®ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.config = Config()
        self.sqs_service = SQSService(self.config)
        self.s3_service = S3Service(self.config)
        self.opensearch_service = OpenSearchService(self.config)
        self.metrics_service = MetricsService(self.config)
        self.processor_factory = ProcessorFactory()

        self.shutdown_event = threading.Event()
        self.executor = ThreadPoolExecutor(
            max_workers=self.config.MAX_WORKERS
        )

        # ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³è¨­å®š
        signal.signal(signal.SIGTERM, self._shutdown_handler)
        signal.signal(signal.SIGINT, self._shutdown_handler)

        logger.info("File Processor initialized",
                   config=self.config.to_dict())

    def _shutdown_handler(self, signum, frame):
        """ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
        logger.info(f"Received signal {signum}, initiating shutdown...")
        self.shutdown_event.set()

    def run(self):
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ«ãƒ¼ãƒ—"""
        logger.info("Starting File Processor...")

        while not self.shutdown_event.is_set():
            try:
                # SQSã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
                messages = self.sqs_service.receive_messages(
                    max_messages=10,
                    wait_time=20  # ãƒ­ãƒ³ã‚°ãƒãƒ¼ãƒªãƒ³ã‚°
                )

                if not messages:
                    continue

                # ä¸¦åˆ—å‡¦ç†
                futures = []
                for message in messages:
                    future = self.executor.submit(
                        self.process_message, message
                    )
                    futures.append((future, message))

                # çµæœã‚’å¾…ã¤
                for future, message in futures:
                    try:
                        future.result(timeout=self.config.PROCESSING_TIMEOUT)
                    except Exception as e:
                        logger.error("Failed to process message",
                                   error=str(e),
                                   message_id=message.get('MessageId'))
                        self.metrics_service.record_error('processing_error')

            except Exception as e:
                logger.error("Error in main loop", error=str(e))
                self.metrics_service.record_error('main_loop_error')
                time.sleep(5)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å°‘ã—å¾…ã¤

        self._cleanup()

    def process_message(self, message: Dict[str, Any]):
        """å€‹åˆ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†"""
        message_id = message.get('MessageId')
        receipt_handle = message.get('ReceiptHandle')

        try:
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒœãƒ‡ã‚£ã‚’ãƒ‘ãƒ¼ã‚¹
            body = json.loads(message.get('Body', '{}'))

            # EventBridgeçµŒç”±ã®S3ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†
            if 'detail' in body:
                s3_event = body['detail']
                bucket = s3_event['bucket']['name']
                key = s3_event['object']['key']
            else:
                # ç›´æ¥ã®S3ã‚¤ãƒ™ãƒ³ãƒˆ
                records = json.loads(body).get('Records', [])
                if not records:
                    logger.warning("No S3 records in message",
                                 message_id=message_id)
                    self.sqs_service.delete_message(receipt_handle)
                    return

                s3_info = records[0]['s3']
                bucket = s3_info['bucket']['name']
                key = s3_info['object']['key']

            logger.info("Processing file",
                       bucket=bucket,
                       key=key,
                       message_id=message_id)

            # å‡¦ç†é–‹å§‹æ™‚é–“ã‚’è¨˜éŒ²
            start_time = time.time()
            self.metrics_service.record_metric('files_processing', 1)

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
            result = self.process_file(bucket, key)

            # OpenSearchã«ç´¢å¼•ä»˜ã‘
            if result['success']:
                self.opensearch_service.index_document(result['document'])

                # å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•
                self.s3_service.move_to_processed(bucket, key)

                # æˆåŠŸãƒ¡ãƒˆãƒªã‚¯ã‚¹
                processing_time = time.time() - start_time
                self.metrics_service.record_metric(
                    'processing_time',
                    processing_time
                )
                self.metrics_service.record_metric('files_processed', 1)

                logger.info("File processed successfully",
                          bucket=bucket,
                          key=key,
                          processing_time=processing_time)
            else:
                # ã‚¨ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ¥ã®å ´æ‰€ã«ç§»å‹•
                self.s3_service.move_to_error(bucket, key)
                self.metrics_service.record_metric('files_failed', 1)

                logger.error("File processing failed",
                           bucket=bucket,
                           key=key,
                           error=result.get('error'))

            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤
            self.sqs_service.delete_message(receipt_handle)

        except Exception as e:
            logger.error("Error processing message",
                       error=str(e),
                       message_id=message_id)

            # ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ãƒˆã‚’å¢—ã‚„ã™
            error_count = int(message.get('Attributes', {})
                            .get('ApproximateReceiveCount', 0))

            if error_count >= self.config.MAX_RETRIES:
                # DLQã«ç§»å‹•ã•ã›ã‚‹ãŸã‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤
                logger.error("Max retries exceeded, moving to DLQ",
                           message_id=message_id,
                           error_count=error_count)
                self.sqs_service.delete_message(receipt_handle)

            raise

    def process_file(self, bucket: str, key: str) -> Dict[str, Any]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            local_path = self.s3_service.download_file(bucket, key)

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
            file_extension = os.path.splitext(key)[1].lower()

            # é©åˆ‡ãªãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’å–å¾—
            processor = self.processor_factory.get_processor(file_extension)

            # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
            extracted_text = processor.extract_text(local_path)

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
            metadata = self.s3_service.get_object_metadata(bucket, key)

            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ
            document = {
                'id': f"{bucket}/{key}",
                'bucket': bucket,
                'key': key,
                'file_name': os.path.basename(key),
                'file_path': key,
                'file_size': metadata.get('ContentLength', 0),
                'file_type': file_extension,
                'content': extracted_text,
                'last_modified': metadata.get('LastModified'),
                'indexed_at': time.time(),
                'metadata': {
                    'content_type': metadata.get('ContentType'),
                    'etag': metadata.get('ETag'),
                    'storage_class': metadata.get('StorageClass')
                }
            }

            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if os.path.exists(local_path):
                os.remove(local_path)

            return {
                'success': True,
                'document': document
            }

        except Exception as e:
            logger.error("Error processing file",
                       bucket=bucket,
                       key=key,
                       error=str(e))
            return {
                'success': False,
                'error': str(e)
            }

    def _cleanup(self):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†"""
        logger.info("Shutting down executor...")
        self.executor.shutdown(wait=True, timeout=30)

        logger.info("Closing connections...")
        self.opensearch_service.close()

        logger.info("File Processor stopped")

def main():
    """ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    processor = FileProcessor()
    processor.run()

if __name__ == "__main__":
    main()
```

### 2. è¨­å®šç®¡ç† (`config.py`)

```python
"""è¨­å®šç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""

import os
import json
from dataclasses import dataclass
from typing import Optional

@dataclass
class Config:
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š"""

    # AWSè¨­å®š
    AWS_REGION: str = os.environ.get('AWS_REGION', 'ap-northeast-1')

    # SQSè¨­å®š
    SQS_QUEUE_URL: str = os.environ.get(
        'SQS_QUEUE_URL',
        'https://sqs.ap-northeast-1.amazonaws.com/123456789012/CIS-FileProcessing-Queue'
    )
    SQS_DLQ_URL: str = os.environ.get(
        'SQS_DLQ_URL',
        'https://sqs.ap-northeast-1.amazonaws.com/123456789012/CIS-FileProcessing-DLQ'
    )

    # S3è¨­å®š
    S3_LANDING_BUCKET: str = os.environ.get(
        'S3_LANDING_BUCKET',
        'cis-filesearch-landing'
    )
    S3_PROCESSED_BUCKET: str = os.environ.get(
        'S3_PROCESSED_BUCKET',
        'cis-filesearch-processed'
    )
    S3_ERROR_BUCKET: str = os.environ.get(
        'S3_ERROR_BUCKET',
        'cis-filesearch-error'
    )

    # OpenSearchè¨­å®š
    OPENSEARCH_ENDPOINT: str = os.environ.get(
        'OPENSEARCH_ENDPOINT',
        'https://search-cis-filesearch.ap-northeast-1.es.amazonaws.com'
    )
    OPENSEARCH_INDEX: str = os.environ.get(
        'OPENSEARCH_INDEX',
        'cis-files'
    )

    # å‡¦ç†è¨­å®š
    MAX_WORKERS: int = int(os.environ.get('MAX_WORKERS', '4'))
    MAX_RETRIES: int = int(os.environ.get('MAX_RETRIES', '3'))
    PROCESSING_TIMEOUT: int = int(os.environ.get('PROCESSING_TIMEOUT', '300'))

    # Tesseractè¨­å®š
    TESSERACT_LANG: str = os.environ.get('TESSERACT_LANG', 'jpn+eng')
    TESSERACT_CONFIG: str = os.environ.get('TESSERACT_CONFIG', '--psm 3')

    # ãƒ­ã‚°è¨­å®š
    LOG_LEVEL: str = os.environ.get('LOG_LEVEL', 'INFO')

    def to_dict(self) -> dict:
        """è¨­å®šã‚’è¾æ›¸ã¨ã—ã¦è¿”ã™"""
        return {
            key: getattr(self, key)
            for key in dir(self)
            if key.isupper()
        }

    @classmethod
    def from_json(cls, json_path: str) -> 'Config':
        """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã‚€"""
        with open(json_path, 'r') as f:
            config_dict = json.load(f)

        config = cls()
        for key, value in config_dict.items():
            if hasattr(config, key):
                setattr(config, key, value)

        return config
```

### 3. PDFå‡¦ç† (`processors/pdf_processor.py`)

```python
"""PDFå‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""

import os
import tempfile
from typing import Optional
import structlog
import PyPDF2
import pdfplumber
from pdf2image import convert_from_path
import pytesseract

from .base import BaseProcessor

logger = structlog.get_logger()

class PDFProcessor(BaseProcessor):
    """PDFå‡¦ç†ã‚¯ãƒ©ã‚¹"""

    def extract_text(self, file_path: str) -> str:
        """PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        text = ""

        try:
            # ã¾ãšpdfplumberã§è©¦ã™ï¼ˆæ—¥æœ¬èªå¯¾å¿œãŒè‰¯ã„ï¼‰
            with pdfplumber.open(file_path) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"

            # ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã§ããªã„å ´åˆã¯OCRã‚’è©¦ã™
            if not text.strip():
                logger.info("No text found, trying OCR",
                          file_path=file_path)
                text = self._extract_with_ocr(file_path)

            return text.strip()

        except Exception as e:
            logger.error("Error processing PDF",
                       file_path=file_path,
                       error=str(e))

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦PyPDF2ã‚’è©¦ã™
            try:
                return self._extract_with_pypdf2(file_path)
            except Exception as e2:
                logger.error("Fallback PDF processing failed",
                           file_path=file_path,
                           error=str(e2))
                raise

    def _extract_with_ocr(self, file_path: str) -> str:
        """OCRã§PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        text = ""

        with tempfile.TemporaryDirectory() as temp_dir:
            # PDFã‚’ç”»åƒã«å¤‰æ›
            images = convert_from_path(
                file_path,
                dpi=300,
                output_folder=temp_dir
            )

            # å„ãƒšãƒ¼ã‚¸ã‚’OCRå‡¦ç†
            for i, image in enumerate(images):
                logger.info(f"Processing page {i+1}/{len(images)} with OCR")

                # Tesseract OCRã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
                page_text = pytesseract.image_to_string(
                    image,
                    lang='jpn+eng',
                    config='--psm 3'
                )

                text += f"--- Page {i+1} ---\n{page_text}\n"

        return text

    def _extract_with_pypdf2(self, file_path: str) -> str:
        """PyPDF2ã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        text = ""

        with open(file_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)

            for page_num in range(len(pdf_reader.pages)):
                page = pdf_reader.pages[page_num]
                text += page.extract_text() + "\n"

        return text
```

### 4. ç”»åƒå‡¦ç† (`processors/image_processor.py`)

```python
"""ç”»åƒå‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆOCRï¼‰"""

from PIL import Image
import pytesseract
import cv2
import numpy as np
import structlog

from .base import BaseProcessor

logger = structlog.get_logger()

class ImageProcessor(BaseProcessor):
    """ç”»åƒå‡¦ç†ã‚¯ãƒ©ã‚¹"""

    SUPPORTED_FORMATS = {
        '.jpg', '.jpeg', '.png', '.gif', '.bmp',
        '.tiff', '.tif', '.webp'
    }

    def extract_text(self, file_path: str) -> str:
        """ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        try:
            # ç”»åƒã‚’èª­ã¿è¾¼ã¿
            image = cv2.imread(file_path)

            # å‰å‡¦ç†
            processed_image = self._preprocess_image(image)

            # Tesseract OCRã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
            text = pytesseract.image_to_string(
                processed_image,
                lang='jpn+eng',
                config='--psm 3 -c preserve_interword_spaces=1'
            )

            # æ¤œå‡ºã•ã‚ŒãŸæ–‡å­—ã®ä¿¡é ¼åº¦ã‚’å–å¾—
            data = pytesseract.image_to_data(
                processed_image,
                lang='jpn+eng',
                output_type=pytesseract.Output.DICT
            )

            # ä¿¡é ¼åº¦ãŒä½ã„å ´åˆã¯è­¦å‘Š
            confidences = [int(conf) for conf in data['conf'] if int(conf) > 0]
            if confidences:
                avg_confidence = sum(confidences) / len(confidences)
                if avg_confidence < 60:
                    logger.warning("Low OCR confidence",
                                 file_path=file_path,
                                 avg_confidence=avg_confidence)

            return text.strip()

        except Exception as e:
            logger.error("Error processing image",
                       file_path=file_path,
                       error=str(e))
            raise

    def _preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """ç”»åƒã®å‰å‡¦ç†ï¼ˆOCRç²¾åº¦å‘ä¸Šï¼‰"""
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # ãƒã‚¤ã‚ºé™¤å»
        denoised = cv2.fastNlMeansDenoising(gray)

        # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆæ”¹å–„ï¼ˆCLAHEï¼‰
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(denoised)

        # äºŒå€¤åŒ–ï¼ˆOtsu's methodï¼‰
        _, binary = cv2.threshold(
            enhanced, 0, 255,
            cv2.THRESH_BINARY + cv2.THRESH_OTSU
        )

        # å‚¾ãè£œæ­£
        corrected = self._deskew(binary)

        return corrected

    def _deskew(self, image: np.ndarray) -> np.ndarray:
        """ç”»åƒã®å‚¾ãè£œæ­£"""
        coords = np.column_stack(np.where(image > 0))
        angle = cv2.minAreaRect(coords)[-1]

        if angle < -45:
            angle = -(90 + angle)
        else:
            angle = -angle

        (h, w) = image.shape[:2]
        center = (w // 2, h // 2)
        M = cv2.getRotationMatrix2D(center, angle, 1.0)
        rotated = cv2.warpAffine(
            image, M, (w, h),
            flags=cv2.INTER_CUBIC,
            borderMode=cv2.BORDER_REPLICATE
        )

        return rotated
```

### 5. SQSã‚µãƒ¼ãƒ“ã‚¹ (`services/sqs_service.py`)

```python
"""SQSæ“ä½œã‚µãƒ¼ãƒ“ã‚¹"""

import json
from typing import List, Dict, Any
import boto3
import structlog
from botocore.exceptions import ClientError

logger = structlog.get_logger()

class SQSService:
    """SQSæ“ä½œã‚’ç®¡ç†ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config):
        self.config = config
        self.sqs_client = boto3.client('sqs', region_name=config.AWS_REGION)
        self.queue_url = config.SQS_QUEUE_URL

    def receive_messages(self,
                        max_messages: int = 10,
                        wait_time: int = 20) -> List[Dict[str, Any]]:
        """SQSã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—"""
        try:
            response = self.sqs_client.receive_message(
                QueueUrl=self.queue_url,
                MaxNumberOfMessages=max_messages,
                WaitTimeSeconds=wait_time,
                AttributeNames=['All'],
                MessageAttributeNames=['All']
            )

            messages = response.get('Messages', [])

            if messages:
                logger.info(f"Received {len(messages)} messages from SQS")

            return messages

        except ClientError as e:
            logger.error("Error receiving messages from SQS",
                       error=str(e))
            raise

    def delete_message(self, receipt_handle: str):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤"""
        try:
            self.sqs_client.delete_message(
                QueueUrl=self.queue_url,
                ReceiptHandle=receipt_handle
            )
            logger.debug("Message deleted from SQS")

        except ClientError as e:
            logger.error("Error deleting message from SQS",
                       error=str(e))
            raise

    def send_to_dlq(self, message: Dict[str, Any], error_reason: str):
        """DLQã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡"""
        try:
            dlq_message = {
                'original_message': message,
                'error_reason': error_reason,
                'timestamp': time.time()
            }

            self.sqs_client.send_message(
                QueueUrl=self.config.SQS_DLQ_URL,
                MessageBody=json.dumps(dlq_message)
            )

            logger.info("Message sent to DLQ",
                       message_id=message.get('MessageId'))

        except ClientError as e:
            logger.error("Error sending message to DLQ",
                       error=str(e))
            raise
```

### 6. èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (`run.sh`)

```bash
#!/bin/bash
# File Processorèµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

# ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
export AWS_REGION=${AWS_REGION:-ap-northeast-1}
export LOG_LEVEL=${LOG_LEVEL:-INFO}

# ä»®æƒ³ç’°å¢ƒã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
source /var/app/cis-file-processor/venv/bin/activate

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•
cd /var/app/cis-file-processor
python main.py
```

## ğŸ“¦ ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ (`requirements.txt`)

```text
# Core
boto3==1.34.0
botocore==1.34.0

# Logging
structlog==24.1.0

# PDF Processing
PyPDF2==3.0.1
pdfplumber==0.10.3
pdf2image==1.16.3

# OCR
pytesseract==0.3.10
Pillow==10.2.0
opencv-python==4.9.0.80
numpy==1.24.3

# Office Documents
python-docx==1.1.0
openpyxl==3.1.2
python-pptx==0.6.23

# OpenSearch
opensearch-py==2.4.2
requests-aws4auth==1.2.3

# Monitoring
prometheus-client==0.19.0

# Testing
pytest==7.4.4
pytest-cov==4.1.0
pytest-mock==3.12.0
moto==4.2.12
```

## ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

### S3ã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

```bash
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°
cd /path/to/your/code
tar -czf file-processor.tar.gz *.py processors/ services/ utils/ requirements.txt

# S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
aws s3 cp file-processor.tar.gz s3://cis-filesearch-deployment/latest/
aws s3 cp config/processor-config.json s3://cis-filesearch-deployment/config/
```

### EC2 User Dataã§ã®è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤

User Dataã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ã§è‡ªå‹•çš„ã«S3ã‹ã‚‰æœ€æ–°ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã¾ã™ã€‚

## ğŸ“Š ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹

### ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹

ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ä»¥ä¸‹ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’CloudWatchã«é€ä¿¡ï¼š

- `files_processing` - å‡¦ç†ä¸­ã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°
- `files_processed` - å‡¦ç†å®Œäº†ãƒ•ã‚¡ã‚¤ãƒ«æ•°
- `files_failed` - å‡¦ç†å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«æ•°
- `processing_time` - ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ™‚é–“
- `ocr_confidence` - OCRä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢

### ãƒ­ã‚°å‡ºåŠ›

æ§‹é€ åŒ–ãƒ­ã‚°ï¼ˆJSONå½¢å¼ï¼‰ã‚’CloudWatch Logsã«é€ä¿¡ï¼š

```json
{
  "timestamp": "2024-01-20T10:30:00Z",
  "level": "INFO",
  "message": "File processed successfully",
  "bucket": "cis-filesearch-landing",
  "key": "documents/report.pdf",
  "processing_time": 12.5,
  "file_size": 2048576
}
```

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### Tesseractè¨€èªãƒ‘ãƒƒã‚¯ç¢ºèª

```bash
tesseract --list-langs
# å‡ºåŠ›ã« jpn ã¨ eng ãŒå«ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
```

### Pythonä¾å­˜é–¢ä¿‚ã®å•é¡Œ

```bash
# ä»®æƒ³ç’°å¢ƒã®å†ä½œæˆ
rm -rf venv
python3.11 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼

```python
# config.pyã§èª¿æ•´
MAX_WORKERS = 2  # ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã‚’æ¸›ã‚‰ã™
```

## âœ… ãƒ†ã‚¹ãƒˆ

### ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

```bash
pytest tests/ -v --cov=./ --cov-report=html
```

### çµ±åˆãƒ†ã‚¹ãƒˆ

```bash
# ãƒ†ã‚¹ãƒˆç”¨SQSãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡
aws sqs send-message \
  --queue-url https://sqs.ap-northeast-1.amazonaws.com/xxx/CIS-FileProcessing-Queue \
  --message-body '{
    "Records": [{
      "s3": {
        "bucket": {"name": "cis-filesearch-landing"},
        "object": {"key": "test/sample.pdf"}
      }
    }]
  }'
```

## ğŸ“š å‚è€ƒãƒªãƒ³ã‚¯

- [Tesseract OCR Documentation](https://github.com/tesseract-ocr/tesseract/wiki)
- [OpenSearch Python Client](https://opensearch.org/docs/latest/clients/python/)
- [Boto3 Documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

Python Workerã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè£…å¾Œã¯ã€[10-spot-interruption-handling-guide.md](./10-spot-interruption-handling-guide.md)ã§Spot Instanceä¸­æ–­ã¸ã®å¯¾å¿œæ–¹æ³•ã‚’ç¢ºèªã—ã¾ã™ã€‚