#!/bin/bash

# =============================================================================
# DLQ Recovery Optimization Script
# =============================================================================
# „Åì„ÅÆ„Çπ„ÇØ„É™„Éó„Éà„ÅØDLQ„É™„Ç´„Éê„É™„Éº„ÇíÊúÄÈÅ©Âåñ„Åó„ÄÅÂá¶ÁêÜÈÄüÂ∫¶„ÇíÂêë‰∏ä„Åï„Åõ„Åæ„Åô
#
# ÊúÄÈÅ©ÂåñÂÜÖÂÆπ:
# 1. „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫„ÅÆÂ¢óÂä†Ôºà10 -> 100Ôºâ
# 2. ‰∏¶ÂàóÂá¶ÁêÜ„ÅÆÊúâÂäπÂåñ
# 3. ÂæÖÊ©üÊôÇÈñì„ÅÆÂâäÊ∏õ
#
# ‰ΩøÁî®ÊñπÊ≥ï:
#   chmod +x optimize_recovery.sh
#   ./optimize_recovery.sh
# =============================================================================

set -e

# ANSI color codes
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
BLUE='\033[0;34m'
NC='\033[0m'

echo -e "${BLUE}‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó${NC}"
echo -e "${BLUE}‚ïë         DLQ Recovery Optimization                              ‚ïë${NC}"
echo -e "${BLUE}‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù${NC}"
echo ""

# ÁèæÂú®„ÅÆ„É™„Ç´„Éê„É™„Éº„Éó„É≠„Çª„Çπ„Çí„ÉÅ„Çß„ÉÉ„ÇØ
echo -e "${YELLOW}Checking current recovery process...${NC}"
CURRENT_PROCESS=$(ps aux | grep "recover_dlq_messages.py" | grep -v grep || true)

if [ ! -z "$CURRENT_PROCESS" ]; then
    echo -e "${GREEN}‚úì Recovery process is running:${NC}"
    echo "$CURRENT_PROCESS"
    echo ""
    echo -e "${YELLOW}Do you want to restart with optimized settings? (y/n)${NC}"
    read -r RESPONSE
    if [ "$RESPONSE" != "y" ]; then
        echo "Optimization cancelled."
        exit 0
    fi
    echo ""
    echo -e "${YELLOW}Stopping current process...${NC}"
    pkill -f "recover_dlq_messages.py" || true
    sleep 2
fi

# ÊúÄÈÅ©Âåñ„Åï„Çå„Åü„É™„Ç´„Éê„É™„Éº„Çπ„ÇØ„É™„Éó„Éà„Çí‰ΩúÊàê
cat > /tmp/optimized_recover.py << 'EOF'
#!/usr/bin/env python3
"""
ÊúÄÈÅ©Âåñ„Åï„Çå„ÅüDLQ„É™„Ç´„Éê„É™„Éº„Çπ„ÇØ„É™„Éó„Éà

ÊîπÂñÑÁÇπ:
- „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫„Çí100„Å´Â¢óÂä†
- ‰∏¶ÂàóÂá¶ÁêÜ„ÅÆÊúâÂäπÂåñÔºà5„Çπ„É¨„ÉÉ„ÉâÔºâ
- ÂæÖÊ©üÊôÇÈñì„ÅÆÊúÄÈÅ©Âåñ
- Ë©≥Á¥∞„Å™„Éó„É≠„Ç∞„É¨„ÇπË°®Á§∫
"""

import boto3
import json
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime

# Configuration
DLQ_URL = "https://sqs.ap-northeast-1.amazonaws.com/590183743917/file-metadata-queue-dlq.fifo"
MAIN_QUEUE_URL = "https://sqs.ap-northeast-1.amazonaws.com/590183743917/file-metadata-queue.fifo"
REGION = "ap-northeast-1"
BATCH_SIZE = 100  # 10„Åã„Çâ100„Å´Â¢óÂä†
MAX_WORKERS = 5   # ‰∏¶Âàó„Çπ„É¨„ÉÉ„ÉâÊï∞
WAIT_TIME = 5     # „Éù„Éº„É™„É≥„Ç∞ÂæÖÊ©üÊôÇÈñìÔºàÁßíÔºâ

# SQS client
sqs = boto3.client('sqs', region_name=REGION)

def get_queue_size(queue_url):
    """„Ç≠„É•„Éº„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏Êï∞„ÇíÂèñÂæó"""
    response = sqs.get_queue_attributes(
        QueueUrl=queue_url,
        AttributeNames=['ApproximateNumberOfMessages']
    )
    return int(response['Attributes']['ApproximateNumberOfMessages'])

def process_batch(batch_num, messages):
    """„É°„ÉÉ„Çª„Éº„Ç∏„Éê„ÉÉ„ÉÅ„ÇíÂá¶ÁêÜ"""
    try:
        # „É°„Ç§„É≥„Ç≠„É•„Éº„Å´ÈÄÅ‰ø°„Åô„Çã„Ç®„É≥„Éà„É™„ÇíÊ∫ñÂÇô
        entries = []
        for i, msg in enumerate(messages):
            entries.append({
                'Id': f'msg-{batch_num}-{i}',
                'MessageBody': msg['Body'],
                'MessageGroupId': json.loads(msg['Body']).get('file_path', f'group-{batch_num}')
            })

        # „É°„Ç§„É≥„Ç≠„É•„Éº„Å´ÈÄÅ‰ø°ÔºàÊúÄÂ§ß10‰ª∂„Åö„Å§Ôºâ
        sent_count = 0
        for i in range(0, len(entries), 10):
            batch = entries[i:i+10]
            sqs.send_message_batch(
                QueueUrl=MAIN_QUEUE_URL,
                Entries=batch
            )
            sent_count += len(batch)

        # DLQ„Åã„ÇâÂâäÈô§
        delete_entries = [
            {'Id': f'del-{i}', 'ReceiptHandle': msg['ReceiptHandle']}
            for i, msg in enumerate(messages)
        ]

        for i in range(0, len(delete_entries), 10):
            batch = delete_entries[i:i+10]
            sqs.delete_message_batch(
                QueueUrl=DLQ_URL,
                Entries=batch
            )

        return sent_count
    except Exception as e:
        print(f"‚ùå Error processing batch {batch_num}: {e}", file=sys.stderr)
        return 0

def main():
    print(f"üöÄ Starting optimized DLQ recovery at {datetime.now().strftime('%H:%M:%S')}")
    print(f"üìä Configuration: Batch size={BATCH_SIZE}, Workers={MAX_WORKERS}")
    print("")

    # ÂàùÊúü„Ç´„Ç¶„É≥„Éà
    initial_count = get_queue_size(DLQ_URL)
    print(f"üìù Initial DLQ messages: {initial_count:,}")
    print("")

    if initial_count == 0:
        print("‚úÖ No messages to recover")
        return

    total_processed = 0
    batch_num = 0
    start_time = time.time()

    while True:
        # „É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂèó‰ø°
        response = sqs.receive_message(
            QueueUrl=DLQ_URL,
            MaxNumberOfMessages=10,  # SQS„ÅÆÊúÄÂ§ßÂÄ§
            WaitTimeSeconds=WAIT_TIME,
            AttributeNames=['All']
        )

        messages = response.get('Messages', [])

        if not messages:
            remaining = get_queue_size(DLQ_URL)
            if remaining == 0:
                print("\n‚úÖ All messages recovered!")
                break
            else:
                print(f"‚è≥ Waiting for messages... ({remaining:,} remaining)")
                time.sleep(2)
                continue

        # „Éê„ÉÉ„ÉÅ„ÇíÂèéÈõÜÔºàBATCH_SIZE„Åæ„ÅßÔºâ
        all_messages = messages
        while len(all_messages) < BATCH_SIZE:
            response = sqs.receive_message(
                QueueUrl=DLQ_URL,
                MaxNumberOfMessages=min(10, BATCH_SIZE - len(all_messages)),
                WaitTimeSeconds=1
            )
            new_messages = response.get('Messages', [])
            if not new_messages:
                break
            all_messages.extend(new_messages)

        # ‰∏¶ÂàóÂá¶ÁêÜ
        batch_num += 1
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            # „É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂ∞è„Åï„ÅÑ„Éê„ÉÉ„ÉÅ„Å´ÂàÜÂâ≤ÔºàSQS„ÅÆÂà∂Èôê„Å´ÂØæÂøúÔºâ
            chunks = [all_messages[i:i+10] for i in range(0, len(all_messages), 10)]
            futures = [
                executor.submit(process_batch, f"{batch_num}-{i}", chunk)
                for i, chunk in enumerate(chunks)
            ]

            # ÁµêÊûú„ÇíÂèéÈõÜ
            for future in as_completed(futures):
                count = future.result()
                total_processed += count

        # ÈÄ≤ÊçóË°®Á§∫
        elapsed = time.time() - start_time
        rate = total_processed / elapsed if elapsed > 0 else 0
        remaining = get_queue_size(DLQ_URL)
        progress = (total_processed / initial_count * 100) if initial_count > 0 else 0
        eta_seconds = (remaining / rate) if rate > 0 else 0
        eta_minutes = int(eta_seconds / 60)

        print(f"üì¶ Batch {batch_num}: Processed {len(all_messages):,} messages")
        print(f"   Total: {total_processed:,}/{initial_count:,} ({progress:.1f}%)")
        print(f"   Rate: {rate:.2f} msg/sec")
        print(f"   Remaining: {remaining:,}")
        print(f"   ETA: ~{eta_minutes} minutes")
        print("")

    # ÊúÄÁµÇÁµ±Ë®à
    total_time = time.time() - start_time
    avg_rate = total_processed / total_time if total_time > 0 else 0

    print("=" * 60)
    print(f"üéâ Recovery completed!")
    print(f"   Total processed: {total_processed:,} messages")
    print(f"   Total time: {int(total_time/60)}m {int(total_time%60)}s")
    print(f"   Average rate: {avg_rate:.2f} msg/sec")
    print("=" * 60)

if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Recovery interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Fatal error: {e}", file=sys.stderr)
        sys.exit(1)
EOF

chmod +x /tmp/optimized_recover.py

echo -e "${GREEN}‚úì Optimized recovery script created${NC}"
echo ""

# „Çπ„ÇØ„É™„Éó„Éà„ÇíÂÆüË°å
echo -e "${YELLOW}Starting optimized recovery...${NC}"
echo -e "${BLUE}Note: This will run in the foreground. Press Ctrl+C to stop.${NC}"
echo ""

sleep 2

python3 /tmp/optimized_recover.py
