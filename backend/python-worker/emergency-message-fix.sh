#!/bin/bash
# ç·Šæ€¥ä¿®æ­£ï¼šSQSãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå‰Šé™¤ã•ã‚Œãªã„å•é¡Œã®ä¿®æ­£

set -e

echo "ğŸš¨ ç·Šæ€¥ä¿®æ­£ï¼šSQSãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ã®å•é¡Œ"
echo "====================================="

export AWS_PROFILE=AdministratorAccess-770923989980
export AWS_REGION=ap-northeast-1

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

INSTANCE_ID="i-0e6ac1e4d535a4ab2"

echo -e "${RED}ç¾åœ¨ã®å•é¡Œ:${NC}"
echo "â€¢ å‡¦ç†ä¸­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: 5ä»¶ï¼ˆå‰Šé™¤ã•ã‚Œãªã„ï¼‰"
echo "â€¢ DLQãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: 8,158ä»¶"
echo "â€¢ æ ¹æœ¬åŸå› : OpenSearchã‚¨ãƒ©ãƒ¼æ™‚ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‰Šé™¤ã•ã‚Œãªã„"
echo ""

# Step 1: ä¿®æ­£ç‰ˆWorkerä½œæˆ
echo -e "${GREEN}Step 1: ä¿®æ­£ç‰ˆWorkerä½œæˆ${NC}"

cat > /tmp/fixed_worker_userdata.sh << 'EOF'
#!/bin/bash
set +e
exec > >(tee /var/log/user-data.log)
exec 2>&1

echo "=== Fixed Worker Deployment Started at $(date) ==="

export AWS_REGION="ap-northeast-1"

# æ—¢å­˜ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢
systemctl stop phased-worker.service 2>/dev/null || true
systemctl stop minimal-worker.service 2>/dev/null || true

# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
yum install -y python3 python3-pip || true
pip3 install boto3==1.26.137 --no-deps || true
pip3 install botocore==1.29.137 --no-deps || true
pip3 install urllib3==1.26.16 || true
pip3 install opensearch-py==2.2.0 --no-deps || true
pip3 install requests==2.28.2 || true

# ä¿®æ­£ç‰ˆWorkerä½œæˆ
cat <<'WORKER' > /opt/fixed_worker.py
#!/usr/bin/env python3
"""
Fixed Worker - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å¿…ãšå‰Šé™¤ã™ã‚‹ä¿®æ­£ç‰ˆ
"""

import boto3
import json
import time
import sys
import os
import traceback
from datetime import datetime

print(f"[{datetime.now()}] Fixed Worker Starting...")

# è¨­å®š
QUEUE_URL = "https://sqs.ap-northeast-1.amazonaws.com/770923989980/cis-filesearch-index-queue"
DLQ_URL = "https://sqs.ap-northeast-1.amazonaws.com/770923989980/cis-filesearch-dlq"
REGION = "ap-northeast-1"
MAX_MESSAGES = 3
OPENSEARCH_ENDPOINT = "https://vpc-cis-filesearch-opensearch-xuupcgptq6a4opklfeh65x3uqe.ap-northeast-1.es.amazonaws.com"
INDEX_NAME = "file-metadata"

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
sqs = boto3.client('sqs', region_name=REGION)
s3 = boto3.client('s3', region_name=REGION)

# OpenSearchè¨­å®šï¼ˆã‚¨ãƒ©ãƒ¼ã‚’è¨±å®¹ï¼‰
OPENSEARCH_AVAILABLE = False
try:
    from opensearchpy import OpenSearch
    opensearch = OpenSearch(
        hosts=[{'host': OPENSEARCH_ENDPOINT.replace('https://', ''), 'port': 443}],
        http_compress=True,
        use_ssl=True,
        verify_certs=True,
        ssl_assert_hostname=False,
        ssl_show_warn=False,
        timeout=30,
        max_retries=1,
        retry_on_timeout=False
    )

    # ãƒ†ã‚¹ãƒˆæ¥ç¶š
    opensearch.info()
    OPENSEARCH_AVAILABLE = True
    print(f"[{datetime.now()}] OpenSearch connected")
except Exception as e:
    print(f"[{datetime.now()}] OpenSearch not available: {e}")
    OPENSEARCH_AVAILABLE = False

# çµ±è¨ˆ
stats = {
    'processed': 0,
    'deleted': 0,
    'indexed': 0,
    'errors': 0,
    'dlq_sent': 0
}

def process_message(message):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ï¼ˆã‚¨ãƒ©ãƒ¼ã§ã‚‚å¿…ãšå‰Šé™¤ï¼‰"""

    message_id = message.get('MessageId')
    receipt_handle = message['ReceiptHandle']

    # å‡¦ç†æˆåŠŸãƒ•ãƒ©ã‚°
    processing_success = False
    error_message = None

    try:
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æœ¬æ–‡ã‚’ãƒ‘ãƒ¼ã‚¹
        body = json.loads(message.get('Body', '{}'))

        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±æŠ½å‡ºï¼ˆS3ã‚¤ãƒ™ãƒ³ãƒˆå½¢å¼ï¼‰
        file_info = None
        if 'Records' in body:
            for record in body['Records']:
                if 's3' in record:
                    s3_info = record['s3']
                    bucket = s3_info.get('bucket', {}).get('name')
                    key = s3_info.get('object', {}).get('key')
                    size = s3_info.get('object', {}).get('size', 0)

                    if bucket and key:
                        file_info = {
                            'file_name': os.path.basename(key),
                            'file_path': key,
                            's3_bucket': bucket,
                            's3_key': key,
                            'file_size': size,
                            'timestamp': datetime.utcnow().isoformat(),
                            'processing_status': 'processed'
                        }

                        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ¤å®š
                        if '.' in key:
                            ext = key.rsplit('.', 1)[-1].lower()
                            file_info['file_type'] = ext

                        print(f"[{datetime.now()}] Processing: {file_info['file_name']}")
                        processing_success = True

        # OpenSearchã¸ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆå¤±æ•—ã‚’è¨±å®¹ï¼‰
        if file_info and OPENSEARCH_AVAILABLE:
            try:
                doc_id = file_info['s3_key'].replace('/', '_')
                opensearch.index(
                    index=INDEX_NAME,
                    id=doc_id,
                    body=file_info,
                    refresh=False  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„
                )
                stats['indexed'] += 1
                print(f"[{datetime.now()}] Indexed: {file_info['file_name']}")
            except Exception as e:
                # OpenSearchã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã¯æˆåŠŸæ‰±ã„ï¼‰
                print(f"[{datetime.now()}] OpenSearch error (ignored): {e}")
                error_message = f"OpenSearch: {str(e)}"

    except json.JSONDecodeError as e:
        error_message = f"Invalid JSON: {e}"
        print(f"[{datetime.now()}] JSON error: {e}")
    except Exception as e:
        error_message = f"Processing error: {e}"
        print(f"[{datetime.now()}] Processing error: {e}")
        traceback.print_exc()

    finally:
        # é‡è¦ï¼šå¿…ãšãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤
        try:
            sqs.delete_message(
                QueueUrl=QUEUE_URL,
                ReceiptHandle=receipt_handle
            )
            stats['deleted'] += 1
            print(f"[{datetime.now()}] Message deleted: {message_id}")

            # ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ãŸå ´åˆã¯DLQã«è¨˜éŒ²ï¼ˆå‰Šé™¤å¾Œï¼‰
            if error_message:
                try:
                    sqs.send_message(
                        QueueUrl=DLQ_URL,
                        MessageBody=json.dumps({
                            'original_message': message,
                            'error': error_message,
                            'timestamp': datetime.utcnow().isoformat()
                        })
                    )
                    stats['dlq_sent'] += 1
                except:
                    pass

        except Exception as e:
            print(f"[{datetime.now()}] CRITICAL: Failed to delete message: {e}")
            stats['errors'] += 1

# ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
print(f"[{datetime.now()}] Starting main loop...")

while True:
    try:
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡
        response = sqs.receive_message(
            QueueUrl=QUEUE_URL,
            MaxNumberOfMessages=MAX_MESSAGES,
            WaitTimeSeconds=10,
            VisibilityTimeout=120  # çŸ­ç¸®ã—ã¦æ—©æœŸãƒªãƒˆãƒ©ã‚¤
        )

        messages = response.get('Messages', [])

        if messages:
            print(f"[{datetime.now()}] Processing {len(messages)} messages")

            for message in messages:
                stats['processed'] += 1
                process_message(message)

                # å®šæœŸçš„ã«çµ±è¨ˆå‡ºåŠ›
                if stats['processed'] % 10 == 0:
                    print(f"[{datetime.now()}] Stats: {stats}")
        else:
            time.sleep(2)

    except KeyboardInterrupt:
        print(f"[{datetime.now()}] Shutting down...")
        break
    except Exception as e:
        print(f"[{datetime.now()}] Main loop error: {e}")
        stats['errors'] += 1
        time.sleep(5)

print(f"[{datetime.now()}] Final stats: {stats}")
WORKER

chmod +x /opt/fixed_worker.py

# ã‚µãƒ¼ãƒ“ã‚¹ä½œæˆ
cat <<'SERVICE' > /etc/systemd/system/fixed-worker.service
[Unit]
Description=Fixed SQS Worker
After=network.target

[Service]
Type=simple
ExecStart=/usr/bin/python3 -u /opt/fixed_worker.py
Restart=on-failure
RestartSec=30
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target
SERVICE

# èµ·å‹•
systemctl daemon-reload
systemctl enable fixed-worker.service
systemctl start fixed-worker.service

echo "=== Fixed Worker Started at $(date) ==="
systemctl status fixed-worker.service --no-pager || true
EOF

echo -e "${GREEN}âœ… ä¿®æ­£ç‰ˆWorkerä½œæˆå®Œäº†${NC}"
echo ""

# Step 2: Launch Templateæ›´æ–°
echo -e "${GREEN}Step 2: Launch Templateæ›´æ–°${NC}"

if [[ "$OSTYPE" == "darwin"* ]]; then
    USER_DATA_BASE64=$(base64 -i /tmp/fixed_worker_userdata.sh)
else
    USER_DATA_BASE64=$(base64 -w0 /tmp/fixed_worker_userdata.sh)
fi

NEW_VERSION=$(aws ec2 create-launch-template-version \
    --launch-template-name cis-filesearch-worker-template \
    --source-version '$Latest' \
    --launch-template-data "{\"UserData\":\"${USER_DATA_BASE64}\"}" \
    --query 'LaunchTemplateVersion.VersionNumber' \
    --output text)

echo "æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä½œæˆ: v$NEW_VERSION"

aws ec2 modify-launch-template \
    --launch-template-name cis-filesearch-worker-template \
    --default-version $NEW_VERSION > /dev/null

echo -e "${GREEN}âœ… Launch Templateæ›´æ–°å®Œäº†${NC}"
echo ""

# Step 3: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å†èµ·å‹•
echo -e "${YELLOW}Step 3: ä¿®æ­£ç‰ˆãƒ‡ãƒ—ãƒ­ã‚¤${NC}"
echo ""
echo -e "${BLUE}ä¿®æ­£å†…å®¹:${NC}"
echo "âœ… ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å¿…ãšå‰Šé™¤ï¼ˆfinallyå¥ï¼‰"
echo "âœ… OpenSearchã‚¨ãƒ©ãƒ¼ã‚’è¨±å®¹"
echo "âœ… ã‚¨ãƒ©ãƒ¼æ™‚ã¯DLQã«è¨˜éŒ²"
echo "âœ… Visibility TimeoutçŸ­ç¸®ï¼ˆ120ç§’ï¼‰"
echo ""

read -p "ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å†èµ·å‹•ã—ã¦ä¿®æ­£ã‚’é©ç”¨ã—ã¾ã™ã‹ï¼Ÿ (y/n): " -n 1 -r
echo ""

if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å†èµ·å‹•ä¸­..."

    aws autoscaling terminate-instance-in-auto-scaling-group \
        --instance-id $INSTANCE_ID \
        --no-should-decrement-desired-capacity > /dev/null

    echo "çµ‚äº†ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡..."

    # æ–°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¾…æ©Ÿ
    for i in {1..10}; do
        sleep 30

        NEW_INSTANCE=$(aws autoscaling describe-auto-scaling-groups \
            --auto-scaling-group-names cis-filesearch-ec2-autoscaling \
            --query 'AutoScalingGroups[0].Instances[?LifecycleState==`InService`].InstanceId' \
            --output text)

        if [ -n "$NEW_INSTANCE" ] && [ "$NEW_INSTANCE" != "$INSTANCE_ID" ]; then
            echo -e "${GREEN}âœ… æ–°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹èµ·å‹•: $NEW_INSTANCE${NC}"
            INSTANCE_ID=$NEW_INSTANCE
            break
        fi

        echo "å¾…æ©Ÿä¸­... ($i/10)"
    done

    # å‡¦ç†é–‹å§‹å¾…æ©Ÿ
    echo "å‡¦ç†é–‹å§‹å¾…æ©Ÿä¸­ï¼ˆ60ç§’ï¼‰..."
    sleep 60

    # çµæœç¢ºèª
    echo ""
    echo -e "${BLUE}å‡¦ç†çŠ¶æ³ç¢ºèª:${NC}"

    # ã‚­ãƒ¥ãƒ¼ã®çŠ¶æ…‹ç¢ºèª
    QUEUE_STATUS=$(aws sqs get-queue-attributes \
        --queue-url https://sqs.ap-northeast-1.amazonaws.com/770923989980/cis-filesearch-index-queue \
        --attribute-names ApproximateNumberOfMessagesNotVisible \
        --region ap-northeast-1 \
        --output json)

    IN_FLIGHT=$(echo $QUEUE_STATUS | jq -r '.Attributes.ApproximateNumberOfMessagesNotVisible')

    echo -e "å‡¦ç†ä¸­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: ${IN_FLIGHT}"

    if [ "$IN_FLIGHT" -eq "0" ]; then
        echo -e "${GREEN}âœ… ä¿®æ­£æˆåŠŸï¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒæ­£ã—ãå‰Šé™¤ã•ã‚Œã¦ã„ã¾ã™${NC}"
    else
        echo -e "${YELLOW}âš  ã¾ã å‡¦ç†ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„${NC}"
    fi

    echo ""
    echo "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:"
    echo "1. DLQã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒªã‚«ãƒãƒªãƒ¼"
    echo "2. ./recover-dlq.sh ã‚’å®Ÿè¡Œ"

else
    echo "ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ"
fi