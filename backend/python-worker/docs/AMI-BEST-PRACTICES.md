# AMIæ§‹æˆãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ - Python Worker

## æ¦‚è¦

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€python-workerã‚’EC2 Auto Scalingã§é‹ç”¨ã™ã‚‹ãŸã‚ã®AMIæ§‹æˆãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚

## ç›®æ¬¡

1. [AMIæ§‹æˆæˆ¦ç•¥](#amiæ§‹æˆæˆ¦ç•¥)
2. [AMIä½œæˆãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ](#amiä½œæˆãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ)
3. [AMIä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ](#amiä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ)
4. [Launch Templateè¨­è¨ˆ](#launch-templateè¨­è¨ˆ)
5. [Auto Scaling Policy](#auto-scaling-policy)
6. [ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³](#ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³)
7. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)

---

## AMIæ§‹æˆæˆ¦ç•¥

### è¨­è¨ˆåŸå‰‡

**ã‚¤ãƒŸãƒ¥ãƒ¼ã‚¿ãƒ–ãƒ«ãƒ»ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£**ã‚’æ¡ç”¨ï¼š
- AMIã«ã¯**ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰ã¨ä¾å­˜é–¢ä¿‚ã‚’å«ã‚ã‚‹**
- **ç’°å¢ƒå¤‰æ•°ã‚„å‹•çš„è¨­å®šã¯User Dataã§æ³¨å…¥**
- AMIæ›´æ–°æ™‚ã¯æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½œæˆï¼ˆãƒ­ãƒ¼ãƒªãƒ³ã‚°ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆï¼‰

### ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ†é›¢

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 4: Runtime Configuration     â”‚  â† User Data (èµ·å‹•æ™‚)
â”‚  - ç’°å¢ƒå¤‰æ•°                          â”‚
â”‚  - SQS_QUEUE_URL                     â”‚
â”‚  - OpenSearchæ¥ç¶šæƒ…å ±                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 3: Application Code          â”‚  â† AMI
â”‚  - python-workerã‚³ãƒ¼ãƒ‰                â”‚
â”‚  - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«(ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 2: Dependencies              â”‚  â† AMI
â”‚  - Python 3.11                       â”‚
â”‚  - pip packages (requirements.txt)   â”‚
â”‚  - Tesseract, Poppler, ImageMagick   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 1: Base OS                   â”‚  â† AMI
â”‚  - Amazon Linux 2023                 â”‚
â”‚  - CloudWatch Agent                  â”‚
â”‚  - åŸºæœ¬ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## AMIä½œæˆãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### âœ… AMIã«å«ã‚ã‚‹ã¹ãã‚‚ã®

#### 1. ã‚ªãƒšãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
- [ ] Amazon Linux 2023 (æœ€æ–°ãƒ‘ãƒƒãƒé©ç”¨æ¸ˆã¿)
- [ ] SSM Agent (ãƒ—ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«)
- [ ] CloudWatch Agent (è¨­å®šæ¸ˆã¿)

#### 2. Pythonç’°å¢ƒ
- [ ] Python 3.11 (å›ºå®šãƒãƒ¼ã‚¸ãƒ§ãƒ³)
- [ ] pip (æœ€æ–°ç‰ˆ)
- [ ] virtualenv (ä»»æ„)

#### 3. ã‚·ã‚¹ãƒ†ãƒ ä¾å­˜é–¢ä¿‚
- [ ] Tesseract OCR (4.1.1+)
  - [ ] æ—¥æœ¬èªè¨€èªãƒ‘ãƒƒã‚¯ (jpn.traineddata)
  - [ ] è‹±èªè¨€èªãƒ‘ãƒƒã‚¯ (eng.traineddata)
- [ ] Poppler-utils (pdf2imageç”¨)
- [ ] ImageMagick (ç”»åƒå‡¦ç†ç”¨)
- [ ] libmagic (ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—æ¤œå‡ºç”¨)

#### 4. Pythonä¾å­˜é–¢ä¿‚
- [ ] requirements.txt ã‹ã‚‰ã™ã¹ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿
- [ ] ãƒãƒ¼ã‚¸ãƒ§ãƒ³å›ºå®š (pip freeze ã§ç¢ºèª)

#### 5. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰
- [ ] `/app/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼æ¸ˆã¿
- [ ] ãƒ•ã‚¡ã‚¤ãƒ«æ‰€æœ‰æ¨©: `appuser:appuser`
- [ ] å®Ÿè¡Œæ¨©é™: `worker.py` ã«å®Ÿè¡Œæ¨©é™ä»˜ä¸

#### 6. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« (ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ)
- [ ] `config.py` (ç’°å¢ƒå¤‰æ•°èª­ã¿å–ã‚Šå¯èƒ½)
- [ ] ãƒ­ã‚°è¨­å®š (CloudWatché€£æº)
- [ ] systemdã‚µãƒ¼ãƒ“ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«

#### 7. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
- [ ] `/app/` - ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
- [ ] `/tmp/file-processor/` - ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (è‡ªå‹•ä½œæˆ)
- [ ] `/var/log/file-processor/` - ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
- [ ] `/usr/local/share/tessdata/` - Tesseractãƒ‡ãƒ¼ã‚¿

#### 8. ç›£è¦–ãƒ»ãƒ­ã‚°
- [ ] CloudWatch Agentã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿
- [ ] CloudWatch Logsè¨­å®š (`/opt/aws/amazon-cloudwatch-agent/etc/`)
- [ ] ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†è¨­å®š

#### 9. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
- [ ] érootãƒ¦ãƒ¼ã‚¶ãƒ¼ (`appuser`) ä½œæˆæ¸ˆã¿
- [ ] SSHå¼·åŒ–è¨­å®š (PasswordAuthentication: no)
- [ ] ä¸è¦ãªã‚µãƒ¼ãƒ“ã‚¹ç„¡åŠ¹åŒ–

#### 10. èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- [ ] `/usr/local/bin/start-worker.sh` (èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ)
- [ ] systemdã‚µãƒ¼ãƒ“ã‚¹å®šç¾© (`file-processor-worker.service`)

### âŒ AMIã«å«ã‚ã‚‹ã¹ãã§ãªã„ã‚‚ã®

#### 1. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æƒ…å ±
- [ ] AWSã‚¯ãƒ¬ãƒ‡ãƒ³ã‚·ãƒ£ãƒ« (IAMãƒ­ãƒ¼ãƒ«ä½¿ç”¨)
- [ ] ç’°å¢ƒå¤‰æ•°ã®å®Ÿéš›ã®å€¤ (SQS_QUEUE_URLç­‰)
- [ ] OpenSearchãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰
- [ ] ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã‚­ãƒ¼

#### 2. ä¸€æ™‚ãƒ‡ãƒ¼ã‚¿
- [ ] `/tmp/` é…ä¸‹ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«
- [ ] ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« (`/var/log/`)
- [ ] ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«
- [ ] `.pyc` ãƒ•ã‚¡ã‚¤ãƒ« (å‰Šé™¤æ¨å¥¨)

#### 3. ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å›ºæœ‰ãƒ‡ãƒ¼ã‚¿
- [ ] ãƒ›ã‚¹ãƒˆå
- [ ] IPã‚¢ãƒ‰ãƒ¬ã‚¹
- [ ] SSH Host Keys (èµ·å‹•æ™‚ã«å†ç”Ÿæˆ)

#### 4. é–‹ç™ºãƒ„ãƒ¼ãƒ«
- [ ] git
- [ ] ãƒ†ã‚¹ãƒˆãƒ„ãƒ¼ãƒ« (pytestç­‰)
- [ ] é–‹ç™ºç”¨ã‚¨ãƒ‡ã‚£ã‚¿

### ğŸš€ User Dataã§è¨­å®šã™ã¹ãã‚‚ã®

#### 1. ç’°å¢ƒå¤‰æ•°
```bash
export AWS_REGION="ap-northeast-1"
export S3_BUCKET="cis-filesearch-storage"
export SQS_QUEUE_URL="https://sqs.ap-northeast-1.amazonaws.com/123456789012/file-processing-queue"
export OPENSEARCH_ENDPOINT="https://search-xxx.ap-northeast-1.es.amazonaws.com"
export OPENSEARCH_INDEX="file-index"
export LOG_LEVEL="INFO"
```

#### 2. å‹•çš„è¨­å®š
- Auto Scalingã‚°ãƒ«ãƒ¼ãƒ—å
- ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ID
- Availability Zone

#### 3. èµ·å‹•æ™‚å‡¦ç†
- CloudWatch Agentã®èµ·å‹•
- ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æœ‰åŠ¹åŒ–
- Workerèµ·å‹•

---

## AMIä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### 1. AMIãƒ“ãƒ«ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# scripts/build-ami.sh
# AMIä½œæˆå‰ã®æº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -euo pipefail

echo "==================================="
echo "AMI Build Preparation Script"
echo "==================================="

# å¤‰æ•°å®šç¾©
APP_DIR="/app"
APP_USER="appuser"
PYTHON_VERSION="3.11"

# 1. OSã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ
echo "[1/10] Updating OS packages..."
sudo dnf update -y

# 2. ã‚·ã‚¹ãƒ†ãƒ ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
echo "[2/10] Installing system dependencies..."
sudo dnf install -y \
    python${PYTHON_VERSION} \
    python${PYTHON_VERSION}-pip \
    poppler-utils \
    ImageMagick \
    ImageMagick-devel \
    file-devel \
    wget \
    tar \
    htop \
    jq

# 3. Tesseract OCRã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
echo "[3/10] Installing Tesseract OCR..."
bash scripts/install-tesseract-al2023.sh

# 4. CloudWatch Agentã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
echo "[4/10] Installing CloudWatch Agent..."
wget -q https://s3.amazonaws.com/amazoncloudwatch-agent/amazon_linux/amd64/latest/amazon-cloudwatch-agent.rpm
sudo rpm -U ./amazon-cloudwatch-agent.rpm
rm amazon-cloudwatch-agent.rpm

# 5. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½œæˆ
echo "[5/10] Creating application user..."
if ! id -u $APP_USER > /dev/null 2>&1; then
    sudo useradd -m -u 1000 -s /bin/bash $APP_USER
fi

# 6. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ä½œæˆ
echo "[6/10] Creating directory structure..."
sudo mkdir -p $APP_DIR
sudo mkdir -p /var/log/file-processor
sudo mkdir -p /tmp/file-processor
sudo chown -R $APP_USER:$APP_USER $APP_DIR /var/log/file-processor /tmp/file-processor

# 7. Pythonä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
echo "[7/10] Installing Python dependencies..."
sudo pip${PYTHON_VERSION} install --upgrade pip
sudo pip${PYTHON_VERSION} install --no-cache-dir -r requirements.txt

# 8. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰ã®ã‚³ãƒ”ãƒ¼
echo "[8/10] Copying application code..."
sudo cp -r . $APP_DIR/
sudo chown -R $APP_USER:$APP_USER $APP_DIR
sudo chmod +x $APP_DIR/worker.py

# 9. systemdã‚µãƒ¼ãƒ“ã‚¹ã®è¨­å®š
echo "[9/10] Configuring systemd service..."
sudo cp scripts/file-processor-worker.service /etc/systemd/system/
sudo systemctl daemon-reload
sudo systemctl enable file-processor-worker.service

# 10. CloudWatch Agentè¨­å®š
echo "[10/10] Configuring CloudWatch Agent..."
sudo cp scripts/cloudwatch-agent-config.json /opt/aws/amazon-cloudwatch-agent/etc/
sudo systemctl enable amazon-cloudwatch-agent

echo "==================================="
echo "AMI Build Preparation Complete!"
echo "==================================="
echo ""
echo "Next steps:"
echo "1. Review configuration"
echo "2. Run: sudo bash scripts/ami-cleanup.sh"
echo "3. Create AMI from EC2 console or AWS CLI"
```

### 2. AMIã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# scripts/ami-cleanup.sh
# AMIä½œæˆå‰ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -euo pipefail

echo "==================================="
echo "AMI Cleanup Script"
echo "==================================="

# 1. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
echo "[1/8] Removing temporary files..."
sudo rm -rf /tmp/*
sudo rm -rf /var/tmp/*
sudo rm -rf /tmp/file-processor/*

# 2. ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
echo "[2/8] Clearing log files..."
sudo find /var/log -type f -name "*.log" -exec truncate -s 0 {} \;
sudo rm -rf /var/log/file-processor/*

# 3. Pythonã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å‰Šé™¤
echo "[3/8] Removing Python cache..."
sudo find /app -type d -name __pycache__ -exec rm -rf {} + 2>/dev/null || true
sudo find /app -type f -name "*.pyc" -delete 2>/dev/null || true
sudo find /app -type f -name "*.pyo" -delete 2>/dev/null || true

# 4. ã‚³ãƒãƒ³ãƒ‰å±¥æ­´ã®å‰Šé™¤
echo "[4/8] Clearing command history..."
sudo rm -f /root/.bash_history
rm -f /home/ec2-user/.bash_history
rm -f /home/appuser/.bash_history

# 5. SSH Host Keysã®å‰Šé™¤ (èµ·å‹•æ™‚ã«å†ç”Ÿæˆ)
echo "[5/8] Removing SSH host keys..."
sudo rm -f /etc/ssh/ssh_host_*

# 6. ã‚¯ãƒ©ã‚¦ãƒ‰initãƒ­ã‚°ã®å‰Šé™¤
echo "[6/8] Clearing cloud-init logs..."
sudo rm -rf /var/lib/cloud/instances/*
sudo rm -rf /var/log/cloud-init*.log

# 7. ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å‰Šé™¤
echo "[7/8] Cleaning package cache..."
sudo dnf clean all

# 8. ç’°å¢ƒå¤‰æ•°ã®å‰Šé™¤ç¢ºèª
echo "[8/8] Checking for sensitive environment variables..."
if env | grep -E "(SQS_QUEUE_URL|OPENSEARCH|AWS_ACCESS_KEY)" > /dev/null; then
    echo "âš ï¸  WARNING: Sensitive environment variables detected!"
    env | grep -E "(SQS_QUEUE_URL|OPENSEARCH|AWS_ACCESS_KEY)"
    echo "Please unset these variables before creating AMI."
    exit 1
fi

echo "==================================="
echo "AMI Cleanup Complete!"
echo "==================================="
echo ""
echo "âœ… Ready to create AMI"
echo ""
echo "Create AMI using AWS CLI:"
echo "aws ec2 create-image \\"
echo "  --instance-id i-xxxxxxxxx \\"
echo "  --name \"python-worker-v$(date +%Y%m%d-%H%M%S)\" \\"
echo "  --description \"Python Worker for File Processing\" \\"
echo "  --no-reboot"
```

### 3. User Dataèµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# scripts/user-data.sh
# EC2èµ·å‹•æ™‚ã«å®Ÿè¡Œã•ã‚Œã‚‹User Dataã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -euo pipefail

# ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
exec > >(tee -a /var/log/user-data.log)
exec 2>&1

echo "==================================="
echo "User Data Execution Started"
echo "Date: $(date)"
echo "==================================="

# 1. ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
echo "[1/6] Setting environment variables..."
cat << 'EOF' > /etc/profile.d/file-processor.sh
export AWS_REGION="ap-northeast-1"
export S3_BUCKET="cis-filesearch-storage"
export SQS_QUEUE_URL="https://sqs.ap-northeast-1.amazonaws.com/123456789012/file-processing-queue"
export OPENSEARCH_ENDPOINT="https://search-xxx.ap-northeast-1.es.amazonaws.com"
export OPENSEARCH_INDEX="file-index"
export LOG_LEVEL="INFO"
export TEMP_DIR="/tmp/file-processor"
export MAX_FILE_SIZE_MB="100"
export MAX_WORKERS="4"
export PROCESSING_TIMEOUT="300"
EOF

chmod +x /etc/profile.d/file-processor.sh
source /etc/profile.d/file-processor.sh

# 2. ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
echo "[2/6] Retrieving instance metadata..."
INSTANCE_ID=$(ec2-metadata --instance-id | cut -d " " -f 2)
AZ=$(ec2-metadata --availability-zone | cut -d " " -f 2)
REGION=$(ec2-metadata --availability-zone | cut -d " " -f 2 | sed 's/[a-z]$//')

echo "Instance ID: $INSTANCE_ID"
echo "Availability Zone: $AZ"
echo "Region: $REGION"

# 3. CloudWatch Agentã®èµ·å‹•
echo "[3/6] Starting CloudWatch Agent..."
# CloudWatch Agentè¨­å®šã‚’å‹•çš„ã«ç”Ÿæˆ
cat << EOF > /opt/aws/amazon-cloudwatch-agent/etc/cloudwatch-config.json
{
  "logs": {
    "logs_collected": {
      "files": {
        "collect_list": [
          {
            "file_path": "/var/log/file-processor.log",
            "log_group_name": "/aws/ec2/file-processor",
            "log_stream_name": "${INSTANCE_ID}",
            "timezone": "Local"
          },
          {
            "file_path": "/var/log/user-data.log",
            "log_group_name": "/aws/ec2/file-processor",
            "log_stream_name": "${INSTANCE_ID}-userdata",
            "timezone": "Local"
          }
        ]
      }
    }
  },
  "metrics": {
    "namespace": "FileProcessor",
    "metrics_collected": {
      "cpu": {
        "measurement": [{"name": "cpu_usage_idle", "rename": "CPU_IDLE", "unit": "Percent"}],
        "totalcpu": false
      },
      "disk": {
        "measurement": [{"name": "used_percent", "rename": "DISK_USED", "unit": "Percent"}],
        "resources": ["/"]
      },
      "mem": {
        "measurement": [{"name": "mem_used_percent", "rename": "MEM_USED", "unit": "Percent"}]
      }
    },
    "append_dimensions": {
      "InstanceId": "${INSTANCE_ID}",
      "InstanceType": "\${aws:InstanceType}",
      "AutoScalingGroupName": "\${aws:AutoScalingGroupName}"
    }
  }
}
EOF

sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl \
    -a fetch-config \
    -m ec2 \
    -s \
    -c file:/opt/aws/amazon-cloudwatch-agent/etc/cloudwatch-config.json

# 4. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ç¢ºèª
echo "[4/6] Verifying health..."
python3.11 /app/worker.py --validate-only
if [ $? -ne 0 ]; then
    echo "âŒ Configuration validation failed!"
    exit 1
fi

# 5. Workerèµ·å‹•
echo "[5/6] Starting File Processor Worker..."
sudo systemctl start file-processor-worker.service
sudo systemctl status file-processor-worker.service

# 6. èµ·å‹•ç¢ºèª
echo "[6/6] Verifying worker startup..."
sleep 10
if sudo systemctl is-active --quiet file-processor-worker.service; then
    echo "âœ… Worker started successfully"
else
    echo "âŒ Worker failed to start"
    sudo journalctl -u file-processor-worker.service -n 50
    exit 1
fi

echo "==================================="
echo "User Data Execution Completed"
echo "Date: $(date)"
echo "==================================="
```

---

## Launch Templateè¨­è¨ˆ

### å®Œå…¨ç‰ˆ Launch Template (JSON)

```json
{
  "LaunchTemplateName": "python-worker-template-v1",
  "VersionDescription": "Production-ready Python Worker for File Processing",
  "LaunchTemplateData": {
    "ImageId": "ami-xxxxxxxxxxxxxxxxx",
    "InstanceType": "c5.xlarge",
    "IamInstanceProfile": {
      "Name": "FileProcessorWorkerRole"
    },
    "SecurityGroupIds": [
      "sg-xxxxxxxxxxxxxxxxx"
    ],
    "KeyName": "your-key-pair",
    "Monitoring": {
      "Enabled": true
    },
    "EbsOptimized": true,
    "BlockDeviceMappings": [
      {
        "DeviceName": "/dev/xvda",
        "Ebs": {
          "VolumeSize": 30,
          "VolumeType": "gp3",
          "Iops": 3000,
          "Throughput": 125,
          "DeleteOnTermination": true,
          "Encrypted": true
        }
      }
    ],
    "MetadataOptions": {
      "HttpTokens": "required",
      "HttpPutResponseHopLimit": 1,
      "InstanceMetadataTags": "enabled"
    },
    "TagSpecifications": [
      {
        "ResourceType": "instance",
        "Tags": [
          {
            "Key": "Name",
            "Value": "python-worker"
          },
          {
            "Key": "Environment",
            "Value": "production"
          },
          {
            "Key": "Application",
            "Value": "file-processor"
          },
          {
            "Key": "ManagedBy",
            "Value": "AutoScaling"
          }
        ]
      },
      {
        "ResourceType": "volume",
        "Tags": [
          {
            "Key": "Name",
            "Value": "python-worker-volume"
          }
        ]
      }
    ],
    "UserData": "IyEvYmluL2Jhc2gKIyBCYXNlNjQgZW5jb2RlZCB1c2VyLWRhdGEuc2ggc2NyaXB0"
  }
}
```

### Launch Template (Terraform HCL)

```hcl
# terraform/launch_template.tf

resource "aws_launch_template" "python_worker" {
  name_prefix   = "python-worker-"
  description   = "Launch template for Python Worker Auto Scaling"
  image_id      = var.ami_id
  instance_type = "c5.xlarge"

  iam_instance_profile {
    name = aws_iam_instance_profile.worker_profile.name
  }

  vpc_security_group_ids = [aws_security_group.worker_sg.id]

  key_name = var.key_pair_name

  monitoring {
    enabled = true
  }

  ebs_optimized = true

  block_device_mappings {
    device_name = "/dev/xvda"

    ebs {
      volume_size           = 30
      volume_type           = "gp3"
      iops                  = 3000
      throughput            = 125
      delete_on_termination = true
      encrypted             = true
      kms_key_id            = aws_kms_key.ebs_key.arn
    }
  }

  metadata_options {
    http_tokens                 = "required"
    http_put_response_hop_limit = 1
    instance_metadata_tags      = "enabled"
  }

  tag_specifications {
    resource_type = "instance"

    tags = merge(
      var.common_tags,
      {
        Name        = "python-worker"
        Environment = var.environment
        Application = "file-processor"
        ManagedBy   = "AutoScaling"
      }
    )
  }

  tag_specifications {
    resource_type = "volume"

    tags = merge(
      var.common_tags,
      {
        Name = "python-worker-volume"
      }
    )
  }

  user_data = base64encode(templatefile("${path.module}/user-data.sh.tpl", {
    aws_region            = var.aws_region
    s3_bucket             = var.s3_bucket
    sqs_queue_url         = aws_sqs_queue.file_processing.url
    opensearch_endpoint   = aws_opensearch_domain.files.endpoint
    opensearch_index      = var.opensearch_index
    log_level             = var.log_level
    cloudwatch_log_group  = aws_cloudwatch_log_group.worker.name
  }))

  lifecycle {
    create_before_destroy = true
  }
}

# IAM Instance Profile
resource "aws_iam_instance_profile" "worker_profile" {
  name = "file-processor-worker-profile"
  role = aws_iam_role.worker_role.name
}

# IAM Role
resource "aws_iam_role" "worker_role" {
  name = "file-processor-worker-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Principal = {
          Service = "ec2.amazonaws.com"
        }
        Action = "sts:AssumeRole"
      }
    ]
  })
}

# IAM Policy
resource "aws_iam_role_policy" "worker_policy" {
  name = "file-processor-worker-policy"
  role = aws_iam_role.worker_role.id

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Action = [
          "s3:GetObject",
          "s3:PutObject",
          "s3:ListBucket"
        ]
        Resource = [
          aws_s3_bucket.storage.arn,
          "${aws_s3_bucket.storage.arn}/*"
        ]
      },
      {
        Effect = "Allow"
        Action = [
          "sqs:ReceiveMessage",
          "sqs:DeleteMessage",
          "sqs:GetQueueAttributes",
          "sqs:ChangeMessageVisibility"
        ]
        Resource = aws_sqs_queue.file_processing.arn
      },
      {
        Effect = "Allow"
        Action = [
          "es:ESHttpPost",
          "es:ESHttpPut",
          "es:ESHttpGet"
        ]
        Resource = "${aws_opensearch_domain.files.arn}/*"
      },
      {
        Effect = "Allow"
        Action = [
          "logs:CreateLogGroup",
          "logs:CreateLogStream",
          "logs:PutLogEvents",
          "logs:DescribeLogStreams"
        ]
        Resource = "arn:aws:logs:*:*:log-group:/aws/ec2/file-processor*"
      },
      {
        Effect = "Allow"
        Action = [
          "cloudwatch:PutMetricData"
        ]
        Resource = "*"
      }
    ]
  })
}
```

### ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—é¸å®šã‚¬ã‚¤ãƒ‰

| ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ— | vCPU | ãƒ¡ãƒ¢ãƒª | æ¨å¥¨ç”¨é€” | ã‚³ã‚¹ãƒˆ |
|-------------------|------|--------|---------|--------|
| `t3.large` | 2 | 8 GB | é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆ | $ |
| `c5.xlarge` | 4 | 8 GB | æœ¬ç•ª (æ¨å¥¨) | $$ |
| `c5.2xlarge` | 8 | 16 GB | é«˜è² è· (å¤§é‡å‡¦ç†) | $$$ |
| `c6i.xlarge` | 4 | 8 GB | æœ¬ç•ª (æœ€æ–°ä¸–ä»£) | $$ |

**æ¨å¥¨**: `c5.xlarge` (ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆæœ€é©åŒ–ã€4 vCPUã€8 GB RAM)
- OCRå‡¦ç†ã¯CPUé›†ç´„çš„
- MAX_WORKERS=4ã«æœ€é©
- ã‚³ã‚¹ãƒˆåŠ¹ç‡è‰¯å¥½

---

## Auto Scaling Policy

### SQSãƒ™ãƒ¼ã‚¹ã®Target Tracking Scaling

```hcl
# terraform/autoscaling.tf

resource "aws_autoscaling_group" "python_worker" {
  name                = "python-worker-asg"
  vpc_zone_identifier = var.private_subnet_ids
  target_group_arns   = []  # ALBä¸ä½¿ç”¨

  min_size         = 1
  max_size         = 10
  desired_capacity = 2

  health_check_type         = "EC2"
  health_check_grace_period = 300
  default_cooldown          = 300

  launch_template {
    id      = aws_launch_template.python_worker.id
    version = "$Latest"
  }

  enabled_metrics = [
    "GroupMinSize",
    "GroupMaxSize",
    "GroupDesiredCapacity",
    "GroupInServiceInstances",
    "GroupTotalInstances"
  ]

  tag {
    key                 = "Name"
    value               = "python-worker"
    propagate_at_launch = true
  }

  tag {
    key                 = "Environment"
    value               = var.environment
    propagate_at_launch = true
  }

  lifecycle {
    create_before_destroy = true
  }
}

# Target Tracking Scaling Policy - SQSãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ãƒ™ãƒ¼ã‚¹
resource "aws_autoscaling_policy" "sqs_target_tracking" {
  name                   = "sqs-message-based-scaling"
  autoscaling_group_name = aws_autoscaling_group.python_worker.name
  policy_type            = "TargetTrackingScaling"

  target_tracking_configuration {
    customized_metric_specification {
      metric_dimension {
        name  = "QueueName"
        value = aws_sqs_queue.file_processing.name
      }

      metric_name = "ApproximateNumberOfMessagesVisible"
      namespace   = "AWS/SQS"
      statistic   = "Average"
    }

    target_value     = 100.0  # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚ãŸã‚Š100ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    scale_in_cooldown  = 300  # 5åˆ†
    scale_out_cooldown = 60   # 1åˆ†
  }
}

# Step Scaling Policy - é«˜è² è·æ™‚ã®ç·Šæ€¥ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆ
resource "aws_autoscaling_policy" "scale_out_emergency" {
  name                   = "emergency-scale-out"
  autoscaling_group_name = aws_autoscaling_group.python_worker.name
  policy_type            = "StepScaling"
  adjustment_type        = "PercentChangeInCapacity"

  step_adjustment {
    scaling_adjustment          = 50   # 50%å¢—åŠ 
    metric_interval_lower_bound = 0
    metric_interval_upper_bound = 500
  }

  step_adjustment {
    scaling_adjustment          = 100  # 100%å¢—åŠ  (å€å¢—)
    metric_interval_lower_bound = 500
  }
}

# CloudWatch Alarm - ç·Šæ€¥ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆç”¨
resource "aws_cloudwatch_metric_alarm" "sqs_high_messages" {
  alarm_name          = "sqs-high-message-count"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 1
  metric_name         = "ApproximateNumberOfMessagesVisible"
  namespace           = "AWS/SQS"
  period              = 60
  statistic           = "Average"
  threshold           = 500
  alarm_description   = "Trigger emergency scale-out when SQS messages exceed 500"

  dimensions = {
    QueueName = aws_sqs_queue.file_processing.name
  }

  alarm_actions = [aws_autoscaling_policy.scale_out_emergency.arn]
}

# Scheduled Scaling - äºˆæ¸¬å¯èƒ½ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³
resource "aws_autoscaling_schedule" "scale_up_morning" {
  scheduled_action_name  = "scale-up-morning"
  autoscaling_group_name = aws_autoscaling_group.python_worker.name
  min_size               = 3
  max_size               = 10
  desired_capacity       = 5
  recurrence             = "0 8 * * MON-FRI"  # å¹³æ—¥8:00
}

resource "aws_autoscaling_schedule" "scale_down_evening" {
  scheduled_action_name  = "scale-down-evening"
  autoscaling_group_name = aws_autoscaling_group.python_worker.name
  min_size               = 1
  max_size               = 10
  desired_capacity       = 2
  recurrence             = "0 20 * * *"  # æ¯æ—¥20:00
}
```

### ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å¥¨å€¤

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | æ¨å¥¨å€¤ | èª¬æ˜ |
|-----------|--------|------|
| **min_size** | 1 | æœ€å°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•° (ã‚³ã‚¹ãƒˆå‰Šæ¸›) |
| **max_size** | 10 | æœ€å¤§ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•° (è² è·åˆ¶é™) |
| **desired_capacity** | 2 | é€šå¸¸æ™‚ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•° |
| **target_value** | 100 | ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚ãŸã‚Šã®SQSãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•° |
| **scale_in_cooldown** | 300 | ã‚¹ã‚±ãƒ¼ãƒ«ã‚¤ãƒ³å¾…æ©Ÿæ™‚é–“ (5åˆ†) |
| **scale_out_cooldown** | 60 | ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆå¾…æ©Ÿæ™‚é–“ (1åˆ†) |
| **health_check_grace_period** | 300 | ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çŒ¶äºˆæœŸé–“ (5åˆ†) |

---

## ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

### AMIæ›´æ–°æ™‚ã®ã‚¼ãƒ­ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ãƒ‡ãƒ—ãƒ­ã‚¤

#### æˆ¦ç•¥1: ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ (æ¨å¥¨)

```bash
#!/bin/bash
# scripts/deploy-new-ami.sh
# ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã«ã‚ˆã‚‹AMIæ›´æ–°

set -euo pipefail

NEW_AMI_ID=$1
LAUNCH_TEMPLATE_NAME="python-worker-template-v1"
ASG_NAME="python-worker-asg"

echo "==================================="
echo "Rolling Update Deployment"
echo "New AMI: $NEW_AMI_ID"
echo "==================================="

# 1. æ–°ã—ã„Launch Templateãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ä½œæˆ
echo "[1/5] Creating new Launch Template version..."
aws ec2 create-launch-template-version \
    --launch-template-name $LAUNCH_TEMPLATE_NAME \
    --source-version '$Latest' \
    --launch-template-data "{\"ImageId\":\"$NEW_AMI_ID\"}" \
    --version-description "AMI Update: $NEW_AMI_ID"

# æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å–å¾—
LATEST_VERSION=$(aws ec2 describe-launch-templates \
    --launch-template-names $LAUNCH_TEMPLATE_NAME \
    --query 'LaunchTemplates[0].LatestVersionNumber' \
    --output text)

echo "Created version: $LATEST_VERSION"

# 2. Launch Templateã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æ›´æ–°
echo "[2/5] Setting default version..."
aws ec2 modify-launch-template \
    --launch-template-name $LAUNCH_TEMPLATE_NAME \
    --default-version $LATEST_VERSION

# 3. Auto Scaling Groupã®æ›´æ–°
echo "[3/5] Updating Auto Scaling Group..."
aws autoscaling update-auto-scaling-group \
    --auto-scaling-group-name $ASG_NAME \
    --launch-template LaunchTemplateName=$LAUNCH_TEMPLATE_NAME,Version='$Latest'

# 4. ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã®é–‹å§‹
echo "[4/5] Starting instance refresh..."
REFRESH_ID=$(aws autoscaling start-instance-refresh \
    --auto-scaling-group-name $ASG_NAME \
    --preferences '{
        "MinHealthyPercentage": 90,
        "InstanceWarmup": 300,
        "CheckpointPercentages": [50, 100],
        "CheckpointDelay": 300
    }' \
    --query 'InstanceRefreshId' \
    --output text)

echo "Instance Refresh ID: $REFRESH_ID"

# 5. ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã®é€²æ—ç›£è¦–
echo "[5/5] Monitoring instance refresh progress..."
while true; do
    STATUS=$(aws autoscaling describe-instance-refreshes \
        --auto-scaling-group-name $ASG_NAME \
        --instance-refresh-ids $REFRESH_ID \
        --query 'InstanceRefreshes[0].Status' \
        --output text)

    PERCENTAGE=$(aws autoscaling describe-instance-refreshes \
        --auto-scaling-group-name $ASG_NAME \
        --instance-refresh-ids $REFRESH_ID \
        --query 'InstanceRefreshes[0].PercentageComplete' \
        --output text)

    echo "Status: $STATUS - Progress: ${PERCENTAGE}%"

    if [[ "$STATUS" == "Successful" ]]; then
        echo "âœ… Instance refresh completed successfully!"
        break
    elif [[ "$STATUS" == "Failed" ]] || [[ "$STATUS" == "Cancelled" ]]; then
        echo "âŒ Instance refresh failed: $STATUS"
        exit 1
    fi

    sleep 30
done

echo "==================================="
echo "Deployment Complete!"
echo "==================================="
```

#### æˆ¦ç•¥2: Blue/Green Deployment

```bash
#!/bin/bash
# scripts/blue-green-deploy.sh
# Blue/Green Deploymentã«ã‚ˆã‚‹AMIæ›´æ–°

set -euo pipefail

NEW_AMI_ID=$1
ENVIRONMENT="production"

echo "==================================="
echo "Blue/Green Deployment"
echo "New AMI: $NEW_AMI_ID"
echo "==================================="

# 1. Greenç’°å¢ƒã®Launch Templateä½œæˆ
echo "[1/6] Creating Green Launch Template..."
GREEN_LT_NAME="python-worker-template-green-$(date +%Y%m%d%H%M%S)"

aws ec2 create-launch-template \
    --launch-template-name $GREEN_LT_NAME \
    --version-description "Green environment - AMI: $NEW_AMI_ID" \
    --launch-template-data file://green-launch-template.json

# 2. Green Auto Scaling Groupã®ä½œæˆ
echo "[2/6] Creating Green Auto Scaling Group..."
GREEN_ASG_NAME="python-worker-asg-green"

aws autoscaling create-auto-scaling-group \
    --auto-scaling-group-name $GREEN_ASG_NAME \
    --launch-template LaunchTemplateName=$GREEN_LT_NAME,Version='$Latest' \
    --min-size 1 \
    --max-size 10 \
    --desired-capacity 2 \
    --vpc-zone-identifier "subnet-xxx,subnet-yyy" \
    --health-check-type EC2 \
    --health-check-grace-period 300 \
    --tags Key=Name,Value=python-worker-green Key=Environment,Value=$ENVIRONMENT

# 3. Greenç’°å¢ƒã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
echo "[3/6] Waiting for Green instances to become healthy..."
sleep 300

HEALTHY_COUNT=$(aws autoscaling describe-auto-scaling-groups \
    --auto-scaling-group-names $GREEN_ASG_NAME \
    --query 'AutoScalingGroups[0].Instances[?HealthStatus==`Healthy`] | length(@)' \
    --output text)

if [[ $HEALTHY_COUNT -lt 2 ]]; then
    echo "âŒ Green environment unhealthy. Aborting deployment."
    exit 1
fi

echo "âœ… Green environment healthy ($HEALTHY_COUNT instances)"

# 4. ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®åˆ‡ã‚Šæ›¿ãˆ (SQSæ¥ç¶š)
echo "[4/6] Switching traffic to Green environment..."
# SQSãƒ™ãƒ¼ã‚¹ãªã®ã§ç‰¹åˆ¥ãªåˆ‡ã‚Šæ›¿ãˆä¸è¦
# Blueã¨GreenãŒä¸¡æ–¹SQSã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†é–‹å§‹

# 5. Blueç’°å¢ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³
echo "[5/6] Scaling down Blue environment..."
BLUE_ASG_NAME="python-worker-asg"

aws autoscaling update-auto-scaling-group \
    --auto-scaling-group-name $BLUE_ASG_NAME \
    --min-size 0 \
    --max-size 0 \
    --desired-capacity 0

# Blueã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®çµ‚äº†å¾…æ©Ÿ
sleep 180

# 6. Greenç’°å¢ƒã‚’Blueã«ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³
echo "[6/6] Promoting Green to Blue..."
# Green ASGã®åå‰ã‚’å¤‰æ›´ (ã¾ãŸã¯ã‚¿ã‚°æ›´æ–°)
aws autoscaling update-auto-scaling-group \
    --auto-scaling-group-name $GREEN_ASG_NAME \
    --tags Key=Color,Value=Blue Key=Active,Value=true

echo "==================================="
echo "Blue/Green Deployment Complete!"
echo "==================================="
echo "New Blue ASG: $GREEN_ASG_NAME"
echo "Old Blue ASG: $BLUE_ASG_NAME (scaled to 0)"
```

### CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ (GitHub Actions)

```yaml
# .github/workflows/build-and-deploy-ami.yml

name: Build and Deploy AMI

on:
  push:
    branches:
      - main
    paths:
      - 'backend/python-worker/**'
  workflow_dispatch:
    inputs:
      deployment_strategy:
        description: 'Deployment strategy'
        required: true
        default: 'rolling'
        type: choice
        options:
          - rolling
          - blue-green

env:
  AWS_REGION: ap-northeast-1
  BASE_AMI_ID: ami-0d52744d6551d851e  # Amazon Linux 2023

jobs:
  build-ami:
    name: Build AMI
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    outputs:
      ami_id: ${{ steps.create_ami.outputs.ami_id }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Launch temporary EC2 instance
        id: launch_instance
        run: |
          INSTANCE_ID=$(aws ec2 run-instances \
            --image-id ${{ env.BASE_AMI_ID }} \
            --instance-type t3.large \
            --key-name ${{ secrets.EC2_KEY_NAME }} \
            --subnet-id ${{ secrets.SUBNET_ID }} \
            --security-group-ids ${{ secrets.SG_ID }} \
            --iam-instance-profile Name=FileProcessorBuilderRole \
            --block-device-mappings DeviceName=/dev/xvda,Ebs={VolumeSize=30,VolumeType=gp3} \
            --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value=ami-builder}]' \
            --query 'Instances[0].InstanceId' \
            --output text)

          echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT

          # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®èµ·å‹•å¾…æ©Ÿ
          aws ec2 wait instance-running --instance-ids $INSTANCE_ID
          sleep 60

      - name: Copy files to instance
        run: |
          INSTANCE_IP=$(aws ec2 describe-instances \
            --instance-ids ${{ steps.launch_instance.outputs.instance_id }} \
            --query 'Reservations[0].Instances[0].PublicIpAddress' \
            --output text)

          scp -r -o StrictHostKeyChecking=no \
            backend/python-worker/* ec2-user@$INSTANCE_IP:/home/ec2-user/

      - name: Build AMI
        run: |
          INSTANCE_IP=$(aws ec2 describe-instances \
            --instance-ids ${{ steps.launch_instance.outputs.instance_id }} \
            --query 'Reservations[0].Instances[0].PublicIpAddress' \
            --output text)

          ssh -o StrictHostKeyChecking=no ec2-user@$INSTANCE_IP << 'EOF'
            cd /home/ec2-user
            sudo bash scripts/build-ami.sh
            sudo bash scripts/ami-cleanup.sh
EOF

      - name: Create AMI
        id: create_ami
        run: |
          AMI_ID=$(aws ec2 create-image \
            --instance-id ${{ steps.launch_instance.outputs.instance_id }} \
            --name "python-worker-$(date +%Y%m%d-%H%M%S)" \
            --description "Python Worker for File Processing - Built by GitHub Actions" \
            --no-reboot \
            --tag-specifications 'ResourceType=image,Tags=[{Key=Environment,Value=production},{Key=Application,Value=file-processor},{Key=GitCommit,Value=${{ github.sha }}}]' \
            --query 'ImageId' \
            --output text)

          echo "ami_id=$AMI_ID" >> $GITHUB_OUTPUT

          # AMIä½œæˆå®Œäº†å¾…æ©Ÿ
          aws ec2 wait image-available --image-ids $AMI_ID

      - name: Terminate builder instance
        if: always()
        run: |
          aws ec2 terminate-instances \
            --instance-ids ${{ steps.launch_instance.outputs.instance_id }}

  deploy-ami:
    name: Deploy AMI
    needs: build-ami
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Deploy with Rolling Update
        if: ${{ github.event.inputs.deployment_strategy == 'rolling' || github.event.inputs.deployment_strategy == '' }}
        run: |
          bash scripts/deploy-new-ami.sh ${{ needs.build-ami.outputs.ami_id }}

      - name: Deploy with Blue/Green
        if: ${{ github.event.inputs.deployment_strategy == 'blue-green' }}
        run: |
          bash scripts/blue-green-deploy.sh ${{ needs.build-ami.outputs.ami_id }}

      - name: Smoke tests
        run: |
          # SQSã‚­ãƒ¥ãƒ¼ã«ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
          aws sqs send-message \
            --queue-url ${{ secrets.SQS_QUEUE_URL }} \
            --message-body '{"test": true, "bucket": "test-bucket", "key": "test.pdf"}'

          # å‡¦ç†å®Œäº†ã‚’å¾…æ©Ÿ
          sleep 120

          # CloudWatch Logsã§ã‚¨ãƒ©ãƒ¼ç¢ºèª
          ERROR_COUNT=$(aws logs filter-log-events \
            --log-group-name /aws/ec2/file-processor \
            --start-time $(($(date +%s) * 1000 - 300000)) \
            --filter-pattern "ERROR" \
            --query 'events | length(@)' \
            --output text)

          if [[ $ERROR_COUNT -gt 0 ]]; then
            echo "âŒ Deployment validation failed: $ERROR_COUNT errors found"
            exit 1
          fi

          echo "âœ… Deployment validation passed"
```

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### å•é¡Œ1: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒèµ·å‹•ã—ãªã„

#### ç—‡çŠ¶
- Auto Scalingã§èµ·å‹•ã—ãŸã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒã™ãã«çµ‚äº†
- ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å¤±æ•—

#### åŸå› ã¨å¯¾ç­–

**1. User Dataã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚¨ãƒ©ãƒ¼**

```bash
# User Dataãƒ­ã‚°ã®ç¢ºèª
sudo cat /var/log/user-data.log

# CloudWatch Logsã§ç¢ºèª
aws logs tail /aws/ec2/file-processor --follow
```

**2. IAMãƒ­ãƒ¼ãƒ«æ¨©é™ä¸è¶³**

```bash
# ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã§IAMãƒ­ãƒ¼ãƒ«ç¢ºèª
curl http://169.254.169.254/latest/meta-data/iam/security-credentials/

# å¿…è¦ãªæ¨©é™ã®ç¢ºèª
aws iam get-role-policy \
  --role-name FileProcessorWorkerRole \
  --policy-name FileProcessorWorkerPolicy
```

**3. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—è¨­å®šãƒŸã‚¹**

```bash
# ã‚¢ã‚¦ãƒˆãƒã‚¦ãƒ³ãƒ‰ãƒ«ãƒ¼ãƒ«ç¢ºèª
aws ec2 describe-security-groups \
  --group-ids sg-xxxxxxxxx \
  --query 'SecurityGroups[0].IpPermissionsEgress'
```

### å•é¡Œ2: WorkerãŒèµ·å‹•ã™ã‚‹ãŒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ã—ãªã„

#### ç—‡çŠ¶
- ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯æ­£å¸¸èµ·å‹•
- SQSãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå‡¦ç†ã•ã‚Œãªã„

#### ãƒ‡ãƒãƒƒã‚°æ‰‹é †

```bash
# 1. Workerãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
sudo systemctl status file-processor-worker.service
sudo journalctl -u file-processor-worker.service -f

# 2. ç’°å¢ƒå¤‰æ•°ç¢ºèª
sudo -u appuser env | grep -E "(SQS|OPENSEARCH|S3)"

# 3. SQSæ¥ç¶šãƒ†ã‚¹ãƒˆ
python3.11 << EOF
import boto3
sqs = boto3.client('sqs', region_name='ap-northeast-1')
response = sqs.receive_message(
    QueueUrl='https://sqs.ap-northeast-1.amazonaws.com/xxx/queue',
    MaxNumberOfMessages=1
)
print(response)
EOF

# 4. OpenSearchæ¥ç¶šãƒ†ã‚¹ãƒˆ
curl -X GET "https://your-opensearch-endpoint/_cluster/health?pretty"

# 5. S3ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ
aws s3 ls s3://cis-filesearch-storage/ --region ap-northeast-1
```

### å•é¡Œ3: DLQã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè“„ç©

#### åŸå› åˆ†æ

```bash
# DLQã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è©³ç´°å–å¾—
aws sqs receive-message \
  --queue-url https://sqs.ap-northeast-1.amazonaws.com/xxx/dlq \
  --attribute-names All \
  --message-attribute-names All \
  --max-number-of-messages 10

# ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
aws logs filter-log-events \
  --log-group-name /aws/ec2/file-processor \
  --start-time $(($(date +%s) * 1000 - 3600000)) \
  --filter-pattern "ERROR" \
  | jq -r '.events[].message'
```

#### å¯¾ç­–

**1. å‡¦ç†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå»¶é•·**

```bash
# config.pyã§è¨­å®šå¤‰æ›´
export PROCESSING_TIMEOUT="600"
export SQS_VISIBILITY_TIMEOUT="900"
```

**2. ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯è¿½åŠ **

```python
# worker.py ã«è¿½åŠ 
def process_with_retry(self, message, max_retries=3):
    for attempt in range(max_retries):
        try:
            return self.process_sqs_message(message)
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            time.sleep(2 ** attempt)  # Exponential backoff
```

### å•é¡Œ4: ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼

#### ç—‡çŠ¶
- OOM Killerç™ºå‹•
- ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹äºˆæœŸã›ã¬çµ‚äº†

#### å¯¾ç­–

```bash
# 1. ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ç›£è¦–
free -h
top -o %MEM

# 2. ã‚¹ãƒ¯ãƒƒãƒ—é ˜åŸŸã®è¿½åŠ 
sudo dd if=/dev/zero of=/swapfile bs=1M count=4096
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab

# 3. MAX_WORKERSå‰Šæ¸›
export MAX_WORKERS="2"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ4ã‹ã‚‰å‰Šæ¸›

# 4. å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ¶é™
export MAX_FILE_SIZE_MB="50"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ100ã‹ã‚‰å‰Šæ¸›
```

### å•é¡Œ5: AMIæ›´æ–°å¾Œã«æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒæ®‹ã‚‹

#### ç—‡çŠ¶
- ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆå®Œäº†å¾Œã‚‚æ—§ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒç¨¼åƒ

#### å¯¾ç­–

```bash
# å¤ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ‰‹å‹•çµ‚äº†
aws autoscaling terminate-instance-in-auto-scaling-group \
  --instance-id i-xxxxxxxxx \
  --should-decrement-desired-capacity

# ã¾ãŸã¯ã€å¼·åˆ¶çš„ã«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥
aws autoscaling cancel-instance-refresh \
  --auto-scaling-group-name python-worker-asg

aws autoscaling start-instance-refresh \
  --auto-scaling-group-name python-worker-asg \
  --preferences '{
      "MinHealthyPercentage": 0,
      "InstanceWarmup": 300
  }'
```

### ãƒ‡ãƒãƒƒã‚°ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# scripts/debug-worker.sh
# Workerè¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

echo "==================================="
echo "Python Worker Diagnostics"
echo "==================================="

# ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
echo "[1] System Information"
uname -a
cat /etc/os-release

# ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
echo "[2] Instance Metadata"
ec2-metadata --instance-id
ec2-metadata --instance-type
ec2-metadata --availability-zone

# ç’°å¢ƒå¤‰æ•°
echo "[3] Environment Variables"
env | grep -E "(AWS|SQS|OPENSEARCH|S3)" | sort

# Workerã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹
echo "[4] Worker Service Status"
sudo systemctl status file-processor-worker.service --no-pager

# æœ€æ–°ãƒ­ã‚°
echo "[5] Recent Logs"
sudo journalctl -u file-processor-worker.service -n 50 --no-pager

# ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡
echo "[6] Disk Usage"
df -h

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
echo "[7] Memory Usage"
free -h

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶š
echo "[8] Network Connectivity"
# SQS
aws sqs get-queue-attributes \
  --queue-url ${SQS_QUEUE_URL} \
  --attribute-names All \
  --region ${AWS_REGION} 2>&1 | head -5

# OpenSearch
curl -s -o /dev/null -w "%{http_code}\n" ${OPENSEARCH_ENDPOINT}/_cluster/health

# S3
aws s3 ls s3://${S3_BUCKET}/ --region ${AWS_REGION} | head -5

echo "==================================="
echo "Diagnostics Complete"
echo "==================================="
```

---

## ã¾ã¨ã‚

### ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹è¦ç´„

1. **AMIæ§‹æˆ**
   - ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰ã¨ä¾å­˜é–¢ä¿‚ã‚’AMIã«å«ã‚ã‚‹
   - ç’°å¢ƒå¤‰æ•°ã¯User Dataã§æ³¨å…¥
   - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æƒ…å ±ã¯IAMãƒ­ãƒ¼ãƒ«ä½¿ç”¨

2. **Auto Scaling**
   - SQSãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ãƒ™ãƒ¼ã‚¹ã®Target Tracking
   - min=1, desired=2, max=10
   - ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çŒ¶äºˆæœŸé–“: 5åˆ†

3. **ãƒ‡ãƒ—ãƒ­ã‚¤**
   - ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã‚’æ¨å¥¨
   - MinHealthyPercentage: 90%
   - ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã§è‡ªå‹•åŒ–

4. **ç›£è¦–**
   - CloudWatch Agentå¿…é ˆ
   - ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
   - ãƒ­ã‚°é›†ç´„åŒ–

### ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

AMIä½œæˆå‰:
- [ ] `build-ami.sh` å®Ÿè¡Œ
- [ ] `ami-cleanup.sh` å®Ÿè¡Œ
- [ ] ç’°å¢ƒå¤‰æ•°å‰Šé™¤ç¢ºèª
- [ ] ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ç¢ºèª

ãƒ‡ãƒ—ãƒ­ã‚¤å‰:
- [ ] AMIå‹•ä½œç¢ºèª (æ‰‹å‹•èµ·å‹•ãƒ†ã‚¹ãƒˆ)
- [ ] User Dataã‚¹ã‚¯ãƒªãƒ—ãƒˆæ¤œè¨¼
- [ ] IAMãƒ­ãƒ¼ãƒ«æ¨©é™ç¢ºèª
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—è¨­å®šç¢ºèª

ãƒ‡ãƒ—ãƒ­ã‚¤å¾Œ:
- [ ] ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹èµ·å‹•ç¢ºèª
- [ ] Workerãƒ—ãƒ­ã‚»ã‚¹èµ·å‹•ç¢ºèª
- [ ] SQSãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ç¢ºèª
- [ ] CloudWatch Logsã‚¨ãƒ©ãƒ¼ç¢ºèª
- [ ] ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‹•ä½œç¢ºèª
