#!/usr/bin/env python3
"""
AWS Configuration Verification Script
CIS File Search Application - AWSè¨­å®šç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€AWS Consoleã§è¨­å®šã—ãŸãƒªã‚½ãƒ¼ã‚¹ãŒæ­£ã—ãæ§‹æˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¾ã™ã€‚
"""

import boto3
import json
import sys
from typing import Dict, List, Tuple
from datetime import datetime
import os

# ãƒªãƒ¼ã‚¸ãƒ§ãƒ³è¨­å®š
AWS_REGION = os.getenv('AWS_REGION', 'ap-northeast-1')

# æœŸå¾…ã•ã‚Œã‚‹è¨­å®šå€¤ï¼ˆå®Ÿéš›ã®AWSãƒªã‚½ãƒ¼ã‚¹åã«åŸºã¥ãï¼‰
EXPECTED_CONFIG = {
    'opensearch': {
        'domain_name': 'cis-filesearch-opensearch',  # å®Ÿéš›ã®åå‰
        'instance_type': 't3.medium.search',  # å®Ÿéš›ã®è¨­å®šå€¤
        'instance_count': 1,
        'volume_size': 100,
        'volume_type': 'gp3'
    },
    's3_buckets': [
        'cis-filesearch-s3-landing',    # å®Ÿéš›ã®åå‰
        'cis-filesearch-s3-thumbnail'   # å®Ÿéš›ã®åå‰
    ],
    'sqs_queues': [
        'cis-filesearch-index-queue'    # å®Ÿéš›ã®åå‰
    ],
    'sqs_dlq': 'cis-filesearch-dlq',    # å®Ÿéš›ã®DLQå
    'ec2_auto_scaling': {
        'group_name': 'cis-file-processor-asg',
        'min_size': 0,
        'max_size': 10
    }
}

class AWSConfigVerifier:
    """AWSè¨­å®šç¢ºèªã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.session = boto3.Session(region_name=AWS_REGION)
        self.results = []
        self.errors = []

    def verify_all(self) -> bool:
        """å…¨ã¦ã®è¨­å®šã‚’ç¢ºèª"""
        print("=" * 60)
        print("AWS Configuration Verification for CIS File Search")
        print(f"Region: {AWS_REGION}")
        print(f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)
        print()

        # å„ãƒªã‚½ãƒ¼ã‚¹ã®ç¢ºèª
        self._verify_opensearch()
        self._verify_s3_buckets()
        self._verify_sqs_queues()
        self._verify_eventbridge()
        self._verify_auto_scaling()
        self._verify_iam_roles()
        self._verify_bedrock_access()

        # çµæœã‚µãƒãƒªãƒ¼
        self._print_summary()

        return len(self.errors) == 0

    def _verify_opensearch(self):
        """OpenSearchè¨­å®šç¢ºèª"""
        print("ğŸ” Checking OpenSearch Domain...")
        try:
            client = self.session.client('opensearch')
            domain_name = EXPECTED_CONFIG['opensearch']['domain_name']

            # ãƒ‰ãƒ¡ã‚¤ãƒ³æƒ…å ±å–å¾—
            response = client.describe_domain(DomainName=domain_name)
            domain = response['DomainStatus']  # FIX: DomainConfig -> DomainStatus

            # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ç¢ºèª
            instance_type = domain['ClusterConfig']['InstanceType']
            instance_count = domain['ClusterConfig']['InstanceCount']

            # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ç¢ºèª
            volume_size = domain['EBSOptions']['VolumeSize']
            volume_type = domain['EBSOptions']['VolumeType']

            # OpenSearchãƒãƒ¼ã‚¸ãƒ§ãƒ³å–å¾—
            engine_version = domain.get('EngineVersion', 'Unknown')

            # k-NN ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ç¢ºèª
            # Note: OpenSearch 2.x ä»¥é™ã€k-NNãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹
            # 'knn.plugin.enabled' ã®è¨­å®šã¯ä¸è¦ï¼ˆå¤ã„è¨­å®šæ–¹æ³•ï¼‰
            version_major = int(engine_version.split('.')[0].replace('OpenSearch_', '')) if 'OpenSearch_' in engine_version else 0
            knn_available = version_major >= 2  # OpenSearch 2.xä»¥é™ã¯å¸¸ã«æœ‰åŠ¹

            checks = [
                (instance_type == EXPECTED_CONFIG['opensearch']['instance_type'],
                 f"Instance Type: {instance_type}"),
                (instance_count == EXPECTED_CONFIG['opensearch']['instance_count'],
                 f"Instance Count: {instance_count}"),
                (volume_size == EXPECTED_CONFIG['opensearch']['volume_size'],
                 f"Volume Size: {volume_size} GB"),
                (volume_type == EXPECTED_CONFIG['opensearch']['volume_type'],
                 f"Volume Type: {volume_type}"),
                (True,  # k-NNã¯å¸¸ã«æœ‰åŠ¹ï¼ˆOpenSearch 2.x+ï¼‰
                 f"k-NN Plugin: Available (OpenSearch {engine_version})")
            ]

            for passed, message in checks:
                self._add_result('OpenSearch', message, passed)

            # ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå–å¾—
            endpoint = domain.get('Endpoint', {}).get('Endpoint', 'Not Available')
            print(f"   Endpoint: https://{endpoint}")

        except Exception as e:
            self._add_result('OpenSearch', f"Error: {str(e)}", False)
        print()

    def _verify_s3_buckets(self):
        """S3ãƒã‚±ãƒƒãƒˆè¨­å®šç¢ºèª"""
        print("ğŸª£ Checking S3 Buckets...")
        try:
            s3 = self.session.client('s3')

            for bucket_name in EXPECTED_CONFIG['s3_buckets']:
                try:
                    # ãƒã‚±ãƒƒãƒˆã®å­˜åœ¨ç¢ºèª
                    s3.head_bucket(Bucket=bucket_name)
                    self._add_result('S3 Bucket', f"{bucket_name}: Exists", True)

                    # Event Notificationç¢ºèªï¼ˆlanding bucketã®å ´åˆï¼‰
                    if 'landing' in bucket_name:
                        notification = s3.get_bucket_notification_configuration(Bucket=bucket_name)
                        has_eventbridge = 'EventBridgeConfiguration' in notification
                        self._add_result('S3 EventBridge',
                                       f"{bucket_name}: {'Enabled' if has_eventbridge else 'DISABLED âš ï¸'}",
                                       has_eventbridge)

                    # ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ç¢ºèª
                    versioning = s3.get_bucket_versioning(Bucket=bucket_name)
                    status = versioning.get('Status', 'Disabled')
                    self._add_result('S3 Versioning', f"{bucket_name}: {status}", True)

                    # æš—å·åŒ–ç¢ºèª
                    try:
                        encryption = s3.get_bucket_encryption(Bucket=bucket_name)
                        self._add_result('S3 Encryption', f"{bucket_name}: Enabled", True)
                    except s3.exceptions.ServerSideEncryptionConfigurationNotFoundError:
                        self._add_result('S3 Encryption', f"{bucket_name}: DISABLED âš ï¸", False)

                except s3.exceptions.NoSuchBucket:
                    self._add_result('S3 Bucket', f"{bucket_name}: NOT FOUND âš ï¸", False)
                except Exception as e:
                    self._add_result('S3 Bucket', f"{bucket_name}: Error - {str(e)}", False)

        except Exception as e:
            self._add_result('S3', f"Error: {str(e)}", False)
        print()

    def _verify_sqs_queues(self):
        """SQSã‚­ãƒ¥ãƒ¼è¨­å®šç¢ºèª"""
        print("ğŸ“¨ Checking SQS Queues...")
        try:
            sqs = self.session.client('sqs')

            # ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¥ãƒ¼ã®ç¢ºèª
            for queue_name in EXPECTED_CONFIG['sqs_queues']:
                try:
                    # ã‚­ãƒ¥ãƒ¼URLå–å¾—
                    response = sqs.get_queue_url(QueueName=queue_name)
                    queue_url = response['QueueUrl']
                    self._add_result('SQS Queue', f"{queue_name}: Exists", True)

                    # ã‚­ãƒ¥ãƒ¼å±æ€§å–å¾—
                    attributes = sqs.get_queue_attributes(
                        QueueUrl=queue_url,
                        AttributeNames=['All']
                    )['Attributes']

                    # é‡è¦ãªè¨­å®šç¢ºèª
                    visibility_timeout = int(attributes.get('VisibilityTimeout', 0))
                    message_retention = int(attributes.get('MessageRetentionPeriod', 0)) // 86400  # æ—¥æ•°ã«å¤‰æ›
                    redrive_policy = attributes.get('RedrivePolicy', '')

                    self._add_result('SQS Settings',
                                   f"Visibility Timeout: {visibility_timeout}s",
                                   visibility_timeout >= 300)
                    self._add_result('SQS Settings',
                                   f"Message Retention: {message_retention} days",
                                   message_retention >= 7)

                    # DLQè¨­å®šç¢ºèª
                    has_dlq = 'deadLetterTargetArn' in redrive_policy
                    self._add_result('SQS DLQ',
                                   f"Dead Letter Queue: {'Configured' if has_dlq else 'NOT CONFIGURED âš ï¸'}",
                                   has_dlq)

                except sqs.exceptions.QueueDoesNotExist:
                    self._add_result('SQS Queue', f"{queue_name}: NOT FOUND âš ï¸", False)
                except Exception as e:
                    self._add_result('SQS Queue', f"{queue_name}: Error - {str(e)}", False)

            # DLQã®ç¢ºèª
            dlq_name = EXPECTED_CONFIG['sqs_dlq']
            try:
                response = sqs.get_queue_url(QueueName=dlq_name)
                queue_url = response['QueueUrl']
                self._add_result('SQS DLQ', f"{dlq_name}: Exists", True)

                # DLQã®å±æ€§ç¢ºèª
                attributes = sqs.get_queue_attributes(
                    QueueUrl=queue_url,
                    AttributeNames=['ApproximateNumberOfMessages']
                )['Attributes']

                msg_count = attributes.get('ApproximateNumberOfMessages', '0')
                self._add_result('DLQ Messages', f"Messages in DLQ: {msg_count}", True)

            except sqs.exceptions.QueueDoesNotExist:
                self._add_result('SQS DLQ', f"{dlq_name}: NOT FOUND âš ï¸", False)
            except Exception as e:
                self._add_result('SQS DLQ', f"{dlq_name}: Error - {str(e)}", False)

        except Exception as e:
            self._add_result('SQS', f"Error: {str(e)}", False)
        print()

    def _verify_eventbridge(self):
        """EventBridgeè¨­å®šç¢ºèª"""
        print("ğŸŒ‰ Checking EventBridge Rules...")
        try:
            events = self.session.client('events')

            # ãƒ«ãƒ¼ãƒ«ä¸€è¦§å–å¾—
            response = events.list_rules(Limit=100)
            rules = response.get('Rules', [])

            # S3é–¢é€£ã®ãƒ«ãƒ¼ãƒ«ã‚’æ¢ã™
            s3_rules = [r for r in rules if 's3' in r['Name'].lower() or 'file' in r['Name'].lower()]

            if s3_rules:
                for rule in s3_rules[:3]:  # æœ€å¤§3ã¤ã¾ã§è¡¨ç¤º
                    self._add_result('EventBridge Rule',
                                   f"{rule['Name']}: {rule['State']}",
                                   rule['State'] == 'ENABLED')

                    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç¢ºèª
                    targets = events.list_targets_by_rule(Rule=rule['Name'])
                    for target in targets.get('Targets', []):
                        target_arn = target['Arn']
                        if 'sqs' in target_arn:
                            self._add_result('EventBridge Target', f"â†’ SQS: {target_arn.split(':')[-1]}", True)
            else:
                self._add_result('EventBridge', "No S3-related rules found âš ï¸", False)

        except Exception as e:
            self._add_result('EventBridge', f"Error: {str(e)}", False)
        print()

    def _verify_auto_scaling(self):
        """Auto Scaling Groupè¨­å®šç¢ºèª"""
        print("âš¡ Checking Auto Scaling Groups...")
        try:
            autoscaling = self.session.client('autoscaling')
            ec2 = self.session.client('ec2')

            # Auto Scaling Groupä¸€è¦§å–å¾—
            response = autoscaling.describe_auto_scaling_groups()
            groups = response['AutoScalingGroups']

            # CISé–¢é€£ã®ã‚°ãƒ«ãƒ¼ãƒ—ã‚’æ¢ã™
            cis_groups = [g for g in groups if 'cis' in g['AutoScalingGroupName'].lower()]

            if cis_groups:
                for group in cis_groups:
                    name = group['AutoScalingGroupName']
                    min_size = group['MinSize']
                    max_size = group['MaxSize']
                    desired = group['DesiredCapacity']
                    instances = len(group['Instances'])

                    self._add_result('Auto Scaling', f"{name}", True)
                    self._add_result('ASG Config', f"Min: {min_size}, Max: {max_size}, Desired: {desired}", True)
                    self._add_result('ASG Status', f"Running Instances: {instances}", True)

                    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒãƒªã‚·ãƒ¼ç¢ºèª
                    policies = autoscaling.describe_policies(AutoScalingGroupName=name)
                    if policies['ScalingPolicies']:
                        for policy in policies['ScalingPolicies']:
                            policy_type = policy.get('PolicyType', 'Unknown')
                            self._add_result('Scaling Policy', f"{policy['PolicyName']} ({policy_type})", True)

                    # Launch Templateç¢ºèª
                    if group.get('LaunchTemplate'):
                        lt_id = group['LaunchTemplate']['LaunchTemplateId']
                        lt_version = group['LaunchTemplate']['Version']
                        self._add_result('Launch Template', f"ID: {lt_id}, Version: {lt_version}", True)

                        # Launch Templateè©³ç´°å–å¾—
                        lt_response = ec2.describe_launch_template_versions(
                            LaunchTemplateId=lt_id,
                            Versions=[lt_version]
                        )
                        if lt_response['LaunchTemplateVersions']:
                            lt_data = lt_response['LaunchTemplateVersions'][0]['LaunchTemplateData']
                            instance_type = lt_data.get('InstanceType', 'Unknown')
                            self._add_result('EC2 Type', f"Instance Type: {instance_type}", True)
            else:
                self._add_result('Auto Scaling', "No CIS-related groups found âš ï¸", False)

        except Exception as e:
            self._add_result('Auto Scaling', f"Error: {str(e)}", False)
        print()

    def _verify_iam_roles(self):
        """IAMãƒ­ãƒ¼ãƒ«è¨­å®šç¢ºèª"""
        print("ğŸ” Checking IAM Roles...")
        try:
            iam = self.session.client('iam')

            # EC2ç”¨ã®ãƒ­ãƒ¼ãƒ«ã‚’æ¢ã™ï¼ˆå®Ÿéš›ã®åå‰ã‚’å„ªå…ˆï¼‰
            expected_roles = ['cis-filesearch-worker-role', 'CIS-EC2-FileProcessor-Role', 'cis-ec2-role', 'CISFileProcessorRole']

            for role_name in expected_roles:
                try:
                    role = iam.get_role(RoleName=role_name)
                    self._add_result('IAM Role', f"{role_name}: Found", True)

                    # ã‚¢ã‚¿ãƒƒãƒã•ã‚ŒãŸãƒãƒªã‚·ãƒ¼ç¢ºèª
                    policies = iam.list_attached_role_policies(RoleName=role_name)
                    for policy in policies['AttachedPolicies']:
                        self._add_result('IAM Policy', f"â†’ {policy['PolicyName']}", True)

                    # ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ãƒãƒªã‚·ãƒ¼ç¢ºèª
                    inline_policies = iam.list_role_policies(RoleName=role_name)
                    for policy_name in inline_policies['PolicyNames']:
                        self._add_result('Inline Policy', f"â†’ {policy_name}", True)

                    break  # 1ã¤è¦‹ã¤ã‹ã‚Œã°ååˆ†

                except iam.exceptions.NoSuchEntityException:
                    continue
            else:
                self._add_result('IAM Role', "No EC2 processor role found âš ï¸", False)
                print("   Suggested role name: cis-filesearch-worker-role")

        except Exception as e:
            self._add_result('IAM', f"Error: {str(e)}", False)
        print()

    def _verify_bedrock_access(self):
        """Bedrock ã‚¢ã‚¯ã‚»ã‚¹ç¢ºèª"""
        print("ğŸ¤– Checking Bedrock Access...")
        try:
            bedrock = self.session.client('bedrock')
            bedrock_runtime = self.session.client('bedrock-runtime')

            # ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ç¢ºèª
            try:
                # Titan Multimodal Embeddings ãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª
                model_id = 'amazon.titan-embed-image-v1'

                # ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—ã‚’è©¦ã¿ã‚‹ï¼ˆæ¨©é™ãŒã‚ã‚Œã°æˆåŠŸã™ã‚‹ï¼‰
                response = bedrock.list_foundation_models()
                titan_models = [m for m in response['modelSummaries']
                              if 'titan' in m['modelId'].lower() and 'embed' in m['modelId'].lower()]

                if titan_models:
                    for model in titan_models:
                        self._add_result('Bedrock Model', f"{model['modelId']}: Available", True)
                else:
                    self._add_result('Bedrock Model', "Titan Embeddings model not found âš ï¸", False)

                self._add_result('Bedrock Access', "API Access: OK", True)

            except Exception as e:
                self._add_result('Bedrock Access', f"Limited or No Access: {str(e)}", False)
                print("   Note: Bedrock access may need to be requested through AWS Console")

        except Exception as e:
            self._add_result('Bedrock', f"Error: {str(e)}", False)
        print()

    def _add_result(self, category: str, message: str, passed: bool):
        """çµæœã‚’è¿½åŠ """
        status = "âœ…" if passed else "âŒ"
        print(f"   {status} {message}")

        result = {
            'category': category,
            'message': message,
            'passed': passed
        }
        self.results.append(result)

        if not passed:
            self.errors.append(f"{category}: {message}")

    def _print_summary(self):
        """çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        print("=" * 60)
        print("VERIFICATION SUMMARY")
        print("=" * 60)

        total = len(self.results)
        passed = sum(1 for r in self.results if r['passed'])
        failed = total - passed

        print(f"Total Checks: {total}")
        print(f"Passed: {passed} âœ…")
        print(f"Failed: {failed} âŒ")
        print()

        if self.errors:
            print("âš ï¸ Issues Found:")
            for error in self.errors:
                print(f"   - {error}")
            print()
            print("ğŸ“ Action Required:")
            print("   Please configure the missing resources in AWS Console.")
            print("   Refer to the DataSync documentation for detailed setup steps.")
        else:
            print("ğŸ‰ All checks passed! Your AWS environment is ready.")

        print("=" * 60)


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    verifier = AWSConfigVerifier()
    success = verifier.verify_all()

    if not success:
        print("\nâš ï¸ Some configurations are missing or incorrect.")
        print("Please review the issues above and update your AWS Console settings.")
        sys.exit(1)
    else:
        print("\nâœ… AWS configuration verification completed successfully!")
        print("You can now proceed with running the Python Worker application.")
        sys.exit(0)


if __name__ == "__main__":
    main()