#!/usr/bin/env python3
"""
10ä»¶ã®å®Ÿç”»åƒã‚’ç´ æ—©ãã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¦ã‹ã‚‰å®Ÿç”»åƒã‚’è¿½åŠ 
"""

import boto3
import json
import os
from opensearchpy import OpenSearch, RequestsHttpConnection
from requests_aws4auth import AWS4Auth
import requests
import base64
import time
from typing import List, Dict

# AWSè¨­å®š
REGION = 'ap-northeast-1'
OPENSEARCH_ENDPOINT = 'vpc-cis-filesearch-opensearch-xuupcgptq6a4opklfeh65x3uqe.ap-northeast-1.es.amazonaws.com'
S3_BUCKET = 'cis-filesearch-s3-landing'
INDEX_NAME = 'file-index-v2-knn'

# Bedrockè¨­å®š
BEDROCK_MODEL = 'amazon.titan-embed-image-v1'

def get_aws_credentials():
    """AWSèªè¨¼æƒ…å ±ã‚’å–å¾—"""
    session = boto3.Session()
    credentials = session.get_credentials()
    return credentials

def get_opensearch_client():
    """OpenSearchã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—"""
    credentials = get_aws_credentials()
    awsauth = AWS4Auth(
        credentials.access_key,
        credentials.secret_key,
        REGION,
        'es',
        session_token=credentials.token
    )

    client = OpenSearch(
        hosts=[{'host': OPENSEARCH_ENDPOINT, 'port': 443}],
        http_auth=awsauth,
        use_ssl=True,
        verify_certs=True,
        connection_class=RequestsHttpConnection
    )
    return client

def delete_sample_data(client):
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤"""
    print("ğŸ—‘ï¸  ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ä¸­...")

    # sample_ã§å§‹ã¾ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤
    query = {
        "query": {
            "wildcard": {
                "fileName": "sample_*"
            }
        }
    }

    response = client.delete_by_query(
        index=INDEX_NAME,
        body=query
    )

    deleted = response.get('deleted', 0)
    print(f"âœ… {deleted}ä»¶ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
    return deleted

def find_real_images(limit=10):
    """S3ã‹ã‚‰å®Ÿç”»åƒã‚’æ¤œç´¢"""
    print(f"ğŸ” S3ã‹ã‚‰å®Ÿç”»åƒã‚’{limit}ä»¶æ¤œç´¢ä¸­...")

    s3 = boto3.client('s3')

    # documentsãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ç”»åƒã‚’æ¤œç´¢
    paginator = s3.get_paginator('list_objects_v2')
    page_iterator = paginator.paginate(
        Bucket=S3_BUCKET,
        Prefix='documents/'
    )

    images = []
    for page in page_iterator:
        for obj in page.get('Contents', []):
            key = obj['Key']
            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’é¸æŠï¼ˆjpg, jpeg, pngï¼‰
            if key.lower().endswith(('.jpg', '.jpeg', '.png')) and not key.startswith('documents/thumbnails/'):
                images.append({
                    'key': key,
                    'size': obj['Size'],
                    'modified': obj['LastModified'].isoformat()
                })

                if len(images) >= limit:
                    break

        if len(images) >= limit:
            break

    print(f"âœ… {len(images)}ä»¶ã®å®Ÿç”»åƒã‚’ç™ºè¦‹")
    for img in images[:5]:  # æœ€åˆã®5ä»¶ã‚’è¡¨ç¤º
        print(f"  - {img['key']} ({img['size']/1024:.1f} KB)")
    if len(images) > 5:
        print(f"  ... ä»–{len(images)-5}ä»¶")

    return images[:limit]

def generate_embedding(s3_key):
    """Bedrockã‚’ä½¿ç”¨ã—ã¦ç”»åƒã®embeddingã‚’ç”Ÿæˆ"""
    bedrock = boto3.client('bedrock-runtime', region_name=REGION)
    s3 = boto3.client('s3')

    # S3ã‹ã‚‰ç”»åƒã‚’å–å¾—
    response = s3.get_object(Bucket=S3_BUCKET, Key=s3_key)
    image_bytes = response['Body'].read()

    # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    image_base64 = base64.b64encode(image_bytes).decode('utf-8')

    # Bedrock APIã‚’å‘¼ã³å‡ºã—
    request_body = {
        "inputImage": image_base64
    }

    response = bedrock.invoke_model(
        modelId=BEDROCK_MODEL,
        contentType='application/json',
        accept='application/json',
        body=json.dumps(request_body)
    )

    result = json.loads(response['body'].read())
    return result['embedding']  # 1024æ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«

def index_images(client, images):
    """ç”»åƒã‚’OpenSearchã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹"""
    print(f"ğŸ“ {len(images)}ä»¶ã®ç”»åƒã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ä¸­...")

    success_count = 0
    error_count = 0

    for i, img in enumerate(images, 1):
        try:
            print(f"  [{i}/{len(images)}] {img['key']}ã‚’å‡¦ç†ä¸­...")

            # ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
            embedding = generate_embedding(img['key'])

            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ
            doc = {
                "fileName": os.path.basename(img['key']),
                "filePath": f"s3://{S3_BUCKET}/{img['key']}",
                "fileSize": img['size'],
                "fileType": os.path.splitext(img['key'])[1][1:].lower(),  # æ‹¡å¼µå­
                "modifiedDate": img['modified'],
                "image_vector": embedding,
                "department": "å®Ÿç”»åƒãƒ†ã‚¹ãƒˆ",  # éƒ¨ç½²æƒ…å ±ï¼ˆä»®ï¼‰
                "tags": ["å®Ÿç”»åƒ", "ãƒ†ã‚¹ãƒˆ"]  # ã‚¿ã‚°ï¼ˆä»®ï¼‰
            }

            # OpenSearchã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            doc_id = f"real_img_{i:03d}"  # real_img_001, real_img_002...
            response = client.index(
                index=INDEX_NAME,
                id=doc_id,
                body=doc
            )

            if response['result'] in ['created', 'updated']:
                success_count += 1
                print(f"    âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆåŠŸ (ID: {doc_id})")
            else:
                error_count += 1
                print(f"    âš ï¸  äºˆæœŸã—ãªã„çµæœ: {response['result']}")

        except Exception as e:
            error_count += 1
            print(f"    âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")

        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
        time.sleep(0.5)

    print(f"\nğŸ“Š çµæœ:")
    print(f"  - æˆåŠŸ: {success_count}ä»¶")
    print(f"  - ã‚¨ãƒ©ãƒ¼: {error_count}ä»¶")

    return success_count, error_count

def verify_index(client):
    """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®çŠ¶æ…‹ã‚’ç¢ºèª"""
    print("\nğŸ” ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®çŠ¶æ…‹ã‚’ç¢ºèªä¸­...")

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°ã‚’ç¢ºèª
    response = client.count(index=INDEX_NAME)
    total_docs = response['count']

    # æœ€æ–°ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
    search_response = client.search(
        index=INDEX_NAME,
        body={
            "size": 5,
            "sort": [
                {"modifiedDate": {"order": "desc"}}
            ],
            "_source": ["fileName", "filePath", "fileType"]
        }
    )

    print(f"âœ… ç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {total_docs}ä»¶")
    print("ğŸ“„ æœ€æ–°ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:")
    for hit in search_response['hits']['hits']:
        source = hit['_source']
        print(f"  - {source['fileName']} ({source['fileType']})")

    return total_docs

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 50)
    print("ğŸš€ 10ä»¶ã®å®Ÿç”»åƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 50)

    try:
        # OpenSearchã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ
        client = get_opensearch_client()
        print("âœ… OpenSearchã«æ¥ç¶šæˆåŠŸ")

        # 1. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿å‰Šé™¤
        delete_sample_data(client)

        # 2. å®Ÿç”»åƒã‚’æ¤œç´¢
        images = find_real_images(limit=10)

        if not images:
            print("âŒ å®Ÿç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return

        # 3. ç”»åƒã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
        success, errors = index_images(client, images)

        # 4. æœ€çµ‚ç¢ºèª
        total = verify_index(client)

        print("\n" + "=" * 50)
        print("âœ… å‡¦ç†å®Œäº†ï¼")
        print(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†…ã®ç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {total}ä»¶")
        print("=" * 50)

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()